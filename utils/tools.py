import os

import numpy as np
import torch
import matplotlib.pyplot as plt
import pandas as pd
import math

plt.switch_backend('agg')


def adjust_learning_rate(optimizer, epoch, args):
    # lr = args.learning_rate * (0.2 ** (epoch // 2))
    if args.lradj == 'type1':
        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch - 1) // 1))}
    elif args.lradj == 'type2':
        lr_adjust = {
            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,
            10: 5e-7, 15: 1e-7, 20: 5e-8
        }
    elif args.lradj == 'type3':
        lr_adjust = {epoch: args.learning_rate if epoch < 3 else args.learning_rate * (0.9 ** ((epoch - 3) // 1))}
    elif args.lradj == "cosine":
        lr_adjust = {epoch: args.learning_rate /2 * (1 + math.cos(epoch / args.train_epochs * math.pi))}
    if epoch in lr_adjust.keys():
        lr = lr_adjust[epoch]
        for param_group in optimizer.param_groups:
            param_group['lr'] = lr
        print('Updating learning rate to {}'.format(lr))


class EarlyStopping:
    def __init__(self, patience=7, verbose=False, delta=0):
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.inf
        self.delta = delta

    def __call__(self, val_loss, model, path):
        score = -val_loss
        # æ£€æŸ¥F1åˆ†æ•°æ˜¯å¦è¾¾åˆ°100%ï¼ˆval_lossæ¥è¿‘-1.0ï¼‰
        # ä½¿ç”¨å°çš„epsilonæ¥å¤„ç†æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜
        eps = 1e-5
        if abs(val_loss + 1.0) < eps:  # F1åˆ†æ•°ä¸º100%
            print(f'F1åˆ†æ•°è¾¾åˆ°100%ï¼ç«‹åˆ»ä¿å­˜æ¨¡å‹å¹¶æ—©åœ')
            self.save_checkpoint(val_loss, model, path)
            self.early_stop = True
            return
            
        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, model, path)
        elif score <= self.best_score + self.delta:
            self.counter += 1
            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, model, path)
            self.counter = 0

    def save_checkpoint(self, val_loss, model, path):
        if self.verbose:
            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')
        
        # å®‰å…¨çš„æ¨¡å‹ä¿å­˜æœºåˆ¶ - è§£å†³CUDAå†…å­˜é”™è¯¯
        self._safe_save_model(model, path + '/' + 'checkpoint.pth')
        self.val_loss_min = val_loss
    
    def _safe_save_model(self, model, save_path):
        """
        å®‰å…¨çš„æ¨¡å‹ä¿å­˜æ–¹æ³•ï¼Œå¤„ç†CUDAå†…å­˜é—®é¢˜
        """
        import gc
        import time
        
        max_retries = 3
        for attempt in range(max_retries):
            try:
                print(f"ğŸ”„ å°è¯•ä¿å­˜æ¨¡å‹ (ç¬¬{attempt + 1}æ¬¡)")
                
                # 1. åŒæ­¥CUDAæ“ä½œ
                if torch.cuda.is_available():
                    torch.cuda.synchronize()
                
                # 2. æ¸…ç†GPUå†…å­˜ç¼“å­˜
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    torch.cuda.ipc_collect()
                
                # 3. å¼ºåˆ¶åƒåœ¾å›æ”¶
                gc.collect()
                
                # 4. è·å–æ¨¡å‹çŠ¶æ€å­—å…¸å¹¶ç§»åˆ°CPU
                print("ğŸ“¦ æ­£åœ¨æå–æ¨¡å‹å‚æ•°...")
                if hasattr(model, 'module'):
                    # å¤„ç†DataParallelæ¨¡å‹
                    state_dict = model.module.state_dict()
                else:
                    state_dict = model.state_dict()
                
                # 5. ç¡®ä¿æ‰€æœ‰å‚æ•°éƒ½åœ¨CPUä¸Š
                print("ğŸ’» æ­£åœ¨å°†å‚æ•°ç§»è‡³CPU...")
                cpu_state_dict = {}
                for key, value in state_dict.items():
                    if torch.is_tensor(value):
                        cpu_state_dict[key] = value.cpu().clone()
                    else:
                        cpu_state_dict[key] = value
                
                # 6. å†æ¬¡æ¸…ç†å†…å­˜
                del state_dict
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                gc.collect()
                
                # 7. ä¿å­˜åˆ°æ–‡ä»¶
                print("ğŸ’¾ æ­£åœ¨ä¿å­˜åˆ°æ–‡ä»¶...")
                torch.save(cpu_state_dict, save_path)
                
                # 8. éªŒè¯ä¿å­˜æˆåŠŸ
                if os.path.exists(save_path):
                    file_size = os.path.getsize(save_path) / (1024 * 1024)  # MB
                    print(f"âœ… æ¨¡å‹ä¿å­˜æˆåŠŸ! æ–‡ä»¶å¤§å°: {file_size:.2f} MB")
                    
                    # æ¸…ç†ä¸´æ—¶å˜é‡
                    del cpu_state_dict
                    gc.collect()
                    return True
                else:
                    raise RuntimeError("ä¿å­˜æ–‡ä»¶ä¸å­˜åœ¨")
                    
            except Exception as e:
                print(f"âŒ ä¿å­˜å¤±è´¥ (ç¬¬{attempt + 1}æ¬¡): {e}")
                
                # æ¸…ç†å¯èƒ½çš„æ®‹ç•™å˜é‡
                if 'state_dict' in locals():
                    del state_dict
                if 'cpu_state_dict' in locals():
                    del cpu_state_dict
                
                # å¼ºåˆ¶æ¸…ç†GPUå†…å­˜
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    torch.cuda.ipc_collect()
                gc.collect()
                
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿ï¼š2, 4, 8ç§’
                    print(f"â³ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    print(f"ğŸš¨ æ¨¡å‹ä¿å­˜å¤±è´¥ï¼Œå·²å°è¯• {max_retries} æ¬¡")
                    # å°è¯•ä¿å­˜åˆ°å¤‡ç”¨ä½ç½®
                    backup_path = save_path.replace('.pth', '_backup.pth')
                    try:
                        print(f"ğŸ”„ å°è¯•ä¿å­˜åˆ°å¤‡ç”¨ä½ç½®: {backup_path}")
                        # ä½¿ç”¨æœ€ç®€å•çš„æ–¹å¼ä¿å­˜
                        torch.save(model.cpu().state_dict(), backup_path)
                        print(f"âœ… å¤‡ç”¨ä¿å­˜æˆåŠŸ: {backup_path}")
                        return True
                    except Exception as backup_e:
                        print(f"ğŸš¨ å¤‡ç”¨ä¿å­˜ä¹Ÿå¤±è´¥: {backup_e}")
                        return False
        
        return False


class dotdict(dict):
    """dot.notation access to dictionary attributes"""
    __getattr__ = dict.get
    __setattr__ = dict.__setitem__
    __delattr__ = dict.__delitem__


class StandardScaler():
    def __init__(self, mean, std):
        self.mean = mean
        self.std = std

    def transform(self, data):
        return (data - self.mean) / self.std

    def inverse_transform(self, data):
        return (data * self.std) + self.mean


def visual(true, preds=None, name='./pic/test.pdf'):
    """
    Results visualization
    """
    plt.figure()
    plt.plot(true, label='GroundTruth', linewidth=2)
    if preds is not None:
        plt.plot(preds, label='Prediction', linewidth=2)
    plt.legend()
    plt.savefig(name, bbox_inches='tight')


def adjustment(gt, pred):
    anomaly_state = False
    for i in range(len(gt)):
        if gt[i] == 1 and pred[i] == 1 and not anomaly_state:
            anomaly_state = True
            for j in range(i, 0, -1):
                if gt[j] == 0:
                    break
                else:
                    if pred[j] == 0:
                        pred[j] = 1
            for j in range(i, len(gt)):
                if gt[j] == 0:
                    break
                else:
                    if pred[j] == 0:
                        pred[j] = 1
        elif gt[i] == 0:
            anomaly_state = False
        if anomaly_state:
            pred[i] = 1
    return gt, pred


def cal_accuracy(y_pred, y_true):
    return np.mean(y_pred == y_true)