#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†ç±»é”™è¯¯æ ·æœ¬åˆ†æå·¥å…·
ç”¨äºåˆ†æå’Œå¯è§†åŒ–æ¨¡å‹è¯„ä¼°è¿‡ç¨‹ä¸­ä¿å­˜çš„é”™è¯¯åˆ†ç±»æ ·æœ¬çš„æ—¶åºæ•°æ®

ä½¿ç”¨æ–¹æ³•:
python utils/analyze_misclassified_samples.py --result_dir ./result/0821_2024_DualGAF_DDAHU_DualGAFNet_åŸºå‡†ç‰ˆ_sl96_step96_fd128_extractor-dilated_gaf-adaptive_attention-channel_classifier-mlp_stat-basic_fusion-concat
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import argparse
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

class MisclassifiedSampleAnalyzer:
    """åˆ†ç±»é”™è¯¯æ ·æœ¬åˆ†æå™¨"""
    
    def __init__(self, result_dir):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            result_dir (str): ç»“æœç›®å½•è·¯å¾„ï¼ŒåŒ…å«misclassified_sampleså­ç›®å½•
        """
        self.result_dir = Path(result_dir)
        self.misclassified_dir = self.result_dir / 'misclassified_samples'
        
        if not self.misclassified_dir.exists():
            raise ValueError(f"é”™è¯¯æ ·æœ¬ç›®å½•ä¸å­˜åœ¨: {self.misclassified_dir}")
        
        # åŠ è½½é”™è¯¯æ ·æœ¬æ¦‚è¦ä¿¡æ¯
        self.summary_file = self.misclassified_dir / 'misclassified_samples_summary.csv'
        self.error_stats_file = self.misclassified_dir / 'error_type_statistics.csv'
        
        if self.summary_file.exists():
            self.summary_df = pd.read_csv(self.summary_file)
            print(f"âœ… åŠ è½½é”™è¯¯æ ·æœ¬æ¦‚è¦: {len(self.summary_df)} ä¸ªé”™è¯¯æ ·æœ¬")
        else:
            self.summary_df = None
            print("âš ï¸ æœªæ‰¾åˆ°é”™è¯¯æ ·æœ¬æ¦‚è¦æ–‡ä»¶")
        
        if self.error_stats_file.exists():
            self.error_stats_df = pd.read_csv(self.error_stats_file)
            print(f"âœ… åŠ è½½é”™è¯¯ç±»å‹ç»Ÿè®¡: {len(self.error_stats_df)} ç§é”™è¯¯ç±»å‹")
        else:
            self.error_stats_df = None
            print("âš ï¸ æœªæ‰¾åˆ°é”™è¯¯ç±»å‹ç»Ÿè®¡æ–‡ä»¶")
    
    def show_summary(self):
        """æ˜¾ç¤ºé”™è¯¯æ ·æœ¬æ€»ä½“æ¦‚å†µ"""
        if self.summary_df is None:
            print("âŒ æ— æ³•æ˜¾ç¤ºæ¦‚å†µï¼šç¼ºå°‘æ¦‚è¦æ•°æ®")
            return
        
        print("\n" + "="*80)
        print("ğŸ“Š åˆ†ç±»é”™è¯¯æ ·æœ¬åˆ†ææ¦‚å†µ")
        print("="*80)
        
        # åŸºæœ¬ç»Ÿè®¡
        total_errors = len(self.summary_df)
        has_time_series = self.summary_df['Has_Time_Series'].sum()
        
        print(f"æ€»é”™è¯¯æ ·æœ¬æ•°: {total_errors}")
        print(f"åŒ…å«æ—¶åºæ•°æ®çš„é”™è¯¯æ ·æœ¬: {has_time_series}")
        print(f"æ—¶åºæ•°æ®è¦†ç›–ç‡: {has_time_series/total_errors*100:.1f}%")
        
        # æ•°æ®ç±»å‹åˆ†å¸ƒ
        print(f"\nğŸ“‹ æ•°æ®ç±»å‹åˆ†å¸ƒ:")
        data_type_counts = self.summary_df['Data_Type'].value_counts()
        for data_type, count in data_type_counts.items():
            print(f"  {data_type}: {count} ä¸ªæ ·æœ¬ ({count/total_errors*100:.1f}%)")
        
        # é”™è¯¯ç±»å‹åˆ†å¸ƒ
        if self.error_stats_df is not None:
            print(f"\nğŸ¯ ä¸»è¦é”™è¯¯ç±»å‹ (å‰10å):")
            top_errors = self.error_stats_df.head(10)
            for _, row in top_errors.iterrows():
                print(f"  {row['True_Label_Name']} â†’ {row['Predicted_Label_Name']}: {row['Count']} ä¸ªæ ·æœ¬")
        
        # çœŸå®æ ‡ç­¾åˆ†å¸ƒ
        print(f"\nğŸ“ˆ çœŸå®æ ‡ç­¾é”™è¯¯åˆ†å¸ƒ:")
        true_label_errors = self.summary_df['True_Label_Name'].value_counts()
        for label, count in true_label_errors.items():
            print(f"  {label}: {count} ä¸ªé”™è¯¯æ ·æœ¬")
        
        # é¢„æµ‹æ ‡ç­¾åˆ†å¸ƒ
        print(f"\nğŸ² é¢„æµ‹æ ‡ç­¾é”™è¯¯åˆ†å¸ƒ:")
        pred_label_errors = self.summary_df['Predicted_Label_Name'].value_counts()
        for label, count in pred_label_errors.items():
            print(f"  {label}: {count} ä¸ªé”™è¯¯é¢„æµ‹")
    
    def plot_error_distribution(self, save_plot=True):
        """ç»˜åˆ¶é”™è¯¯åˆ†å¸ƒå›¾"""
        if self.summary_df is None or self.error_stats_df is None:
            print("âŒ æ— æ³•ç»˜åˆ¶åˆ†å¸ƒå›¾ï¼šç¼ºå°‘ç»Ÿè®¡æ•°æ®")
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. é”™è¯¯ç±»å‹çƒ­åŠ›å›¾
        pivot_table = self.error_stats_df.pivot(
            index='True_Label_Name', 
            columns='Predicted_Label_Name', 
            values='Count'
        ).fillna(0)
        
        sns.heatmap(pivot_table, annot=True, fmt='d', cmap='Reds', ax=axes[0,0])
        axes[0,0].set_title('é”™è¯¯åˆ†ç±»çƒ­åŠ›å›¾')
        axes[0,0].set_xlabel('é¢„æµ‹æ ‡ç­¾')
        axes[0,0].set_ylabel('çœŸå®æ ‡ç­¾')
        
        # 2. çœŸå®æ ‡ç­¾é”™è¯¯åˆ†å¸ƒ
        true_label_errors = self.summary_df['True_Label_Name'].value_counts()
        true_label_errors.plot(kind='bar', ax=axes[0,1])
        axes[0,1].set_title('å„ç±»åˆ«çš„é”™è¯¯æ ·æœ¬æ•°é‡')
        axes[0,1].set_xlabel('çœŸå®æ ‡ç­¾')
        axes[0,1].set_ylabel('é”™è¯¯æ ·æœ¬æ•°')
        axes[0,1].tick_params(axis='x', rotation=45)
        
        # 3. é¢„æµ‹ç½®ä¿¡åº¦åˆ†å¸ƒ
        if 'Prob_' in self.summary_df.columns[0] or any('Prob_' in col for col in self.summary_df.columns):
            prob_columns = [col for col in self.summary_df.columns if col.startswith('Prob_')]
            if prob_columns:
                # è®¡ç®—æœ€é«˜é¢„æµ‹æ¦‚ç‡
                prob_values = self.summary_df[prob_columns].values
                max_probs = np.max(prob_values, axis=1)
                
                axes[1,0].hist(max_probs, bins=20, alpha=0.7, edgecolor='black')
                axes[1,0].set_title('é”™è¯¯é¢„æµ‹çš„æœ€é«˜ç½®ä¿¡åº¦åˆ†å¸ƒ')
                axes[1,0].set_xlabel('æœ€é«˜é¢„æµ‹æ¦‚ç‡')
                axes[1,0].set_ylabel('æ ·æœ¬æ•°é‡')
                axes[1,0].axvline(x=0.5, color='red', linestyle='--', alpha=0.7, label='0.5é˜ˆå€¼')
                axes[1,0].legend()
        else:
            axes[1,0].text(0.5, 0.5, 'æ— é¢„æµ‹æ¦‚ç‡æ•°æ®', ha='center', va='center', transform=axes[1,0].transAxes)
            axes[1,0].set_title('é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒï¼ˆæ— æ•°æ®ï¼‰')
        
        # 4. æ•°æ®ç±»å‹åˆ†å¸ƒé¥¼å›¾
        data_type_counts = self.summary_df['Data_Type'].value_counts()
        axes[1,1].pie(data_type_counts.values, labels=data_type_counts.index, autopct='%1.1f%%')
        axes[1,1].set_title('æ•°æ®ç±»å‹åˆ†å¸ƒ')
        
        plt.tight_layout()
        
        if save_plot:
            plot_file = self.result_dir / 'error_distribution_analysis.png'
            plt.savefig(plot_file, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š é”™è¯¯åˆ†å¸ƒå›¾å·²ä¿å­˜: {plot_file}")
        
        plt.show()
    
    def analyze_time_series_sample(self, sample_index=None, true_label=None, pred_label=None):
        """åˆ†æç‰¹å®šé”™è¯¯æ ·æœ¬çš„æ—¶åºæ•°æ®"""
        if self.summary_df is None:
            print("âŒ æ— æ³•åˆ†ææ ·æœ¬ï¼šç¼ºå°‘æ¦‚è¦æ•°æ®")
            return
        
        # æŸ¥æ‰¾æ ·æœ¬
        if sample_index is not None:
            sample_row = self.summary_df[self.summary_df['Sample_Index'] == sample_index]
        elif true_label is not None and pred_label is not None:
            sample_row = self.summary_df[
                (self.summary_df['True_Label_Name'] == true_label) & 
                (self.summary_df['Predicted_Label_Name'] == pred_label)
            ]
        else:
            print("âŒ è¯·æŒ‡å®šsample_indexæˆ–(true_label, pred_label)")
            return
        
        if sample_row.empty:
            print("âŒ æœªæ‰¾åˆ°åŒ¹é…çš„é”™è¯¯æ ·æœ¬")
            return
        
        sample_row = sample_row.iloc[0]  # å–ç¬¬ä¸€ä¸ªåŒ¹é…çš„æ ·æœ¬
        
        if not sample_row['Has_Time_Series']:
            print(f"âŒ æ ·æœ¬ {sample_row['Sample_Index']} æ²¡æœ‰æ—¶åºæ•°æ®")
            return
        
        # åŠ è½½æ—¶åºæ•°æ®
        time_series_file = self.misclassified_dir / f"sample_{sample_row['Sample_Index']}_true_{sample_row['True_Label']}_pred_{sample_row['Predicted_Label']}.csv"
        
        if not time_series_file.exists():
            print(f"âŒ æ—¶åºæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {time_series_file}")
            return
        
        # è¯»å–æ—¶åºæ•°æ®ï¼ˆè·³è¿‡æ³¨é‡Šè¡Œï¼‰
        time_series_df = pd.read_csv(time_series_file, comment='#', index_col=0)
        
        print(f"\nğŸ” æ ·æœ¬ {sample_row['Sample_Index']} æ—¶åºæ•°æ®åˆ†æ")
        print(f"çœŸå®æ ‡ç­¾: {sample_row['True_Label_Name']} ({sample_row['True_Label']})")
        print(f"é¢„æµ‹æ ‡ç­¾: {sample_row['Predicted_Label_Name']} ({sample_row['Predicted_Label']})")
        print(f"æ•°æ®ç±»å‹: {sample_row['Data_Type']}")
        print(f"æ—¶åºæ•°æ®å½¢çŠ¶: {time_series_df.shape}")
        
        # ç»˜åˆ¶æ—¶åºæ•°æ®
        fig, axes = plt.subplots(2, 1, figsize=(15, 10))
        
        # 1. æ‰€æœ‰ä¿¡å·çš„æ—¶åºå›¾
        if time_series_df.shape[1] <= 10:  # å¦‚æœä¿¡å·æ•°é‡ä¸å¤šï¼Œå…¨éƒ¨æ˜¾ç¤º
            for col in time_series_df.columns:
                axes[0].plot(time_series_df.index, time_series_df[col], label=col, alpha=0.7)
            axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        else:  # å¦‚æœä¿¡å·å¤ªå¤šï¼Œåªæ˜¾ç¤ºå‰å‡ ä¸ª
            for i, col in enumerate(time_series_df.columns[:6]):
                axes[0].plot(time_series_df.index, time_series_df[col], label=col, alpha=0.7)
            axes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            axes[0].set_title(f'æ—¶åºæ•°æ® (æ˜¾ç¤ºå‰6ä¸ªä¿¡å·ï¼Œå…±{time_series_df.shape[1]}ä¸ª)')
        
        axes[0].set_title(f'é”™è¯¯æ ·æœ¬ {sample_row["Sample_Index"]} - {sample_row["True_Label_Name"]} â†’ {sample_row["Predicted_Label_Name"]}')
        axes[0].set_xlabel('æ—¶é—´æ­¥')
        axes[0].set_ylabel('ä¿¡å·å€¼')
        axes[0].grid(True, alpha=0.3)
        
        # 2. ç»Ÿè®¡ç‰¹å¾çƒ­åŠ›å›¾
        if time_series_df.shape[1] > 1:
            # è®¡ç®—å„ä¿¡å·çš„ç»Ÿè®¡ç‰¹å¾
            stats = pd.DataFrame({
                'Mean': time_series_df.mean(),
                'Std': time_series_df.std(),
                'Min': time_series_df.min(),
                'Max': time_series_df.max(),
                'Range': time_series_df.max() - time_series_df.min()
            })
            
            # æ ‡å‡†åŒ–ä»¥ä¾¿å¯è§†åŒ–
            stats_normalized = (stats - stats.min()) / (stats.max() - stats.min())
            
            sns.heatmap(stats_normalized.T, annot=True, fmt='.2f', cmap='viridis', ax=axes[1])
            axes[1].set_title('ä¿¡å·ç»Ÿè®¡ç‰¹å¾ (æ ‡å‡†åŒ–)')
            axes[1].set_xlabel('ä¿¡å·')
            axes[1].set_ylabel('ç»Ÿè®¡ç‰¹å¾')
        else:
            axes[1].text(0.5, 0.5, 'å•ä¸€ä¿¡å·ï¼Œæ— æ³•ç»˜åˆ¶ç»Ÿè®¡ç‰¹å¾çƒ­åŠ›å›¾', 
                        ha='center', va='center', transform=axes[1].transAxes)
        
        plt.tight_layout()
        
        # ä¿å­˜å•ä¸ªæ ·æœ¬åˆ†æå›¾
        sample_plot_file = self.result_dir / f'sample_{sample_row["Sample_Index"]}_analysis.png'
        plt.savefig(sample_plot_file, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š æ ·æœ¬åˆ†æå›¾å·²ä¿å­˜: {sample_plot_file}")
        
        plt.show()
        
        return time_series_df
    
    def get_available_samples(self):
        """è·å–å¯ç”¨çš„é”™è¯¯æ ·æœ¬åˆ—è¡¨"""
        if self.summary_df is None:
            print("âŒ æ— æ¦‚è¦æ•°æ®")
            return None
        
        # åªè¿”å›æœ‰æ—¶åºæ•°æ®çš„æ ·æœ¬
        samples_with_ts = self.summary_df[self.summary_df['Has_Time_Series'] == True]
        
        print(f"\nğŸ“‹ å¯ç”¨çš„é”™è¯¯æ ·æœ¬ (å…± {len(samples_with_ts)} ä¸ª):")
        print("æ ·æœ¬ç´¢å¼• | çœŸå®æ ‡ç­¾ â†’ é¢„æµ‹æ ‡ç­¾ | æ•°æ®ç±»å‹")
        print("-" * 60)
        
        for _, row in samples_with_ts.head(20).iterrows():  # åªæ˜¾ç¤ºå‰20ä¸ª
            print(f"{row['Sample_Index']:8d} | {row['True_Label_Name']:12s} â†’ {row['Predicted_Label_Name']:12s} | {row['Data_Type']}")
        
        if len(samples_with_ts) > 20:
            print(f"... è¿˜æœ‰ {len(samples_with_ts) - 20} ä¸ªæ ·æœ¬")
        
        return samples_with_ts
    
    def compare_error_patterns(self, error_type1, error_type2, max_samples=5):
        """æ¯”è¾ƒä¸åŒé”™è¯¯ç±»å‹çš„æ¨¡å¼"""
        if self.summary_df is None:
            print("âŒ æ— æ¦‚è¦æ•°æ®")
            return
        
        # è·å–ä¸¤ç§é”™è¯¯ç±»å‹çš„æ ·æœ¬
        type1_samples = self.summary_df[
            (self.summary_df['True_Label_Name'] == error_type1[0]) & 
            (self.summary_df['Predicted_Label_Name'] == error_type1[1]) &
            (self.summary_df['Has_Time_Series'] == True)
        ]
        
        type2_samples = self.summary_df[
            (self.summary_df['True_Label_Name'] == error_type2[0]) & 
            (self.summary_df['Predicted_Label_Name'] == error_type2[1]) &
            (self.summary_df['Has_Time_Series'] == True)
        ]
        
        if type1_samples.empty or type2_samples.empty:
            print(f"âŒ é”™è¯¯ç±»å‹æ ·æœ¬ä¸è¶³: {error_type1} ({len(type1_samples)} ä¸ª), {error_type2} ({len(type2_samples)} ä¸ª)")
            return
        
        print(f"\nğŸ” æ¯”è¾ƒé”™è¯¯æ¨¡å¼:")
        print(f"ç±»å‹1: {error_type1[0]} â†’ {error_type1[1]} ({len(type1_samples)} ä¸ªæ ·æœ¬)")
        print(f"ç±»å‹2: {error_type2[0]} â†’ {error_type2[1]} ({len(type2_samples)} ä¸ªæ ·æœ¬)")
        
        # éšæœºé€‰æ‹©æ ·æœ¬è¿›è¡Œæ¯”è¾ƒ
        selected_type1 = type1_samples.sample(min(max_samples, len(type1_samples)))
        selected_type2 = type2_samples.sample(min(max_samples, len(type2_samples)))
        
        fig, axes = plt.subplots(2, max_samples, figsize=(max_samples*4, 8))
        if max_samples == 1:
            axes = axes.reshape(-1, 1)
        
        # ç»˜åˆ¶é”™è¯¯ç±»å‹1çš„æ ·æœ¬
        for i, (_, sample) in enumerate(selected_type1.iterrows()):
            if i >= max_samples:
                break
            
            time_series_file = self.misclassified_dir / f"sample_{sample['Sample_Index']}_true_{sample['True_Label']}_pred_{sample['Predicted_Label']}.csv"
            if time_series_file.exists():
                time_series_df = pd.read_csv(time_series_file, comment='#', index_col=0)
                
                # åªç»˜åˆ¶å‰å‡ ä¸ªä¿¡å·
                for j, col in enumerate(time_series_df.columns[:3]):
                    axes[0, i].plot(time_series_df.index, time_series_df[col], alpha=0.7, label=col)
                
                axes[0, i].set_title(f'æ ·æœ¬{sample["Sample_Index"]}\n{error_type1[0]}â†’{error_type1[1]}')
                axes[0, i].grid(True, alpha=0.3)
                axes[0, i].legend()
        
        # ç»˜åˆ¶é”™è¯¯ç±»å‹2çš„æ ·æœ¬
        for i, (_, sample) in enumerate(selected_type2.iterrows()):
            if i >= max_samples:
                break
            
            time_series_file = self.misclassified_dir / f"sample_{sample['Sample_Index']}_true_{sample['True_Label']}_pred_{sample['Predicted_Label']}.csv"
            if time_series_file.exists():
                time_series_df = pd.read_csv(time_series_file, comment='#', index_col=0)
                
                # åªç»˜åˆ¶å‰å‡ ä¸ªä¿¡å·
                for j, col in enumerate(time_series_df.columns[:3]):
                    axes[1, i].plot(time_series_df.index, time_series_df[col], alpha=0.7, label=col)
                
                axes[1, i].set_title(f'æ ·æœ¬{sample["Sample_Index"]}\n{error_type2[0]}â†’{error_type2[1]}')
                axes[1, i].grid(True, alpha=0.3)
                axes[1, i].legend()
        
        plt.tight_layout()
        
        # ä¿å­˜æ¯”è¾ƒå›¾
        compare_plot_file = self.result_dir / f'error_pattern_comparison_{error_type1[0]}_{error_type1[1]}_vs_{error_type2[0]}_{error_type2[1]}.png'
        plt.savefig(compare_plot_file, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š é”™è¯¯æ¨¡å¼æ¯”è¾ƒå›¾å·²ä¿å­˜: {compare_plot_file}")
        
        plt.show()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='åˆ†æåˆ†ç±»é”™è¯¯æ ·æœ¬çš„æ—¶åºæ•°æ®')
    parser.add_argument('--result_dir', type=str, required=True,
                       help='ç»“æœç›®å½•è·¯å¾„')
    parser.add_argument('--action', type=str, default='summary',
                       choices=['summary', 'plot', 'analyze_sample', 'list_samples', 'compare'],
                       help='åˆ†æåŠ¨ä½œ')
    parser.add_argument('--sample_index', type=int, default=None,
                       help='è¦åˆ†æçš„æ ·æœ¬ç´¢å¼•')
    parser.add_argument('--true_label', type=str, default=None,
                       help='çœŸå®æ ‡ç­¾åç§°')
    parser.add_argument('--pred_label', type=str, default=None,
                       help='é¢„æµ‹æ ‡ç­¾åç§°')
    
    args = parser.parse_args()
    
    try:
        analyzer = MisclassifiedSampleAnalyzer(args.result_dir)
        
        if args.action == 'summary':
            analyzer.show_summary()
        
        elif args.action == 'plot':
            analyzer.plot_error_distribution()
        
        elif args.action == 'analyze_sample':
            analyzer.analyze_time_series_sample(args.sample_index, args.true_label, args.pred_label)
        
        elif args.action == 'list_samples':
            analyzer.get_available_samples()
        
        elif args.action == 'compare':
            # ç¤ºä¾‹ï¼šæ¯”è¾ƒæœ€å¸¸è§çš„ä¸¤ç§é”™è¯¯ç±»å‹
            if analyzer.error_stats_df is not None and len(analyzer.error_stats_df) >= 2:
                error1 = (analyzer.error_stats_df.iloc[0]['True_Label_Name'], 
                         analyzer.error_stats_df.iloc[0]['Predicted_Label_Name'])
                error2 = (analyzer.error_stats_df.iloc[1]['True_Label_Name'], 
                         analyzer.error_stats_df.iloc[1]['Predicted_Label_Name'])
                analyzer.compare_error_patterns(error1, error2)
            else:
                print("âŒ é”™è¯¯ç±»å‹ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œæ¯”è¾ƒ")
    
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
