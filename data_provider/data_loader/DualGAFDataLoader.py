import os
import numpy as np
import pandas as pd
import torch
import random
from torch.utils.data import Dataset
from sklearn.preprocessing import MinMaxScaler
import warnings
import pickle
from pyts.image import GramianAngularField
import hashlib  # æ·»åŠ å“ˆå¸Œåº“
import multiprocessing as mp
from multiprocessing import shared_memory
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed
from functools import partial
import time
import sys


class DualGAFDataManager:
    """
    åŒGAFæ•°æ®ç®¡ç†å™¨
    è´Ÿè´£æ•°æ®çš„åŠ è½½ã€å¤„ç†å’ŒæŒä¹…åŒ–ï¼Œåªå¤„ç†ä¸€æ¬¡æ•°æ®
    """
    _instances = {}  # ç±»çº§åˆ«çš„å®ä¾‹ç¼“å­˜
    
    def __new__(cls, args):
        # åŸºäºå…³é”®å‚æ•°ç”Ÿæˆå”¯ä¸€æ ‡è¯†
        key = (
            args.root_path,
            args.seq_len,
            args.step,
            args.test_size,
            getattr(args, 'data_type_method', 'float32')
        )
        
        # å¦‚æœå·²å­˜åœ¨ç›¸åŒé…ç½®çš„å®ä¾‹ï¼Œç›´æ¥è¿”å›
        if key not in cls._instances:
            instance = super().__new__(cls)
            cls._instances[key] = instance
            instance._initialized = False
        return cls._instances[key]
    
    def __init__(self, args):
        # é¿å…é‡å¤åˆå§‹åŒ–
        if self._initialized:
            return
            
        self.args = args
        self.root_path = args.root_path
        self.step = args.step
        self.win_size = args.seq_len
        self.test_size = args.test_size
        
        # æ•°æ®ç±»å‹è½¬æ¢æ–¹æ³•é€‰æ‹©
        self.data_type_method = getattr(args, 'data_type_method', 'float32')
        print(f"ä½¿ç”¨æ•°æ®ç±»å‹è½¬æ¢æ–¹æ³•: {self.data_type_method}")
        
        # å¹¶è¡Œå¤„ç†é…ç½® - å»¶è¿Ÿåˆå§‹åŒ–ï¼ˆåªåœ¨éœ€è¦æ•°æ®å¤„ç†æ—¶æ‰è®¾ç½®ï¼‰
        self.args = args  # ä¿å­˜argså¼•ç”¨ï¼Œç”¨äºå»¶è¿Ÿåˆå§‹åŒ–
        self._parallel_initialized = False

        # æ–‡ä»¶æ ‡ç­¾æ˜ å°„
        self.file_label_map = {
            "AHU_annual_resampled_direct_5min_working.csv": "AHU_annual",
            "coi_bias_-4_annual_resampled_direct_5min_working.csv": "coi_bias_-4",
            "coi_bias_4_annual_direct_5min_working.csv": "coi_bias_4",
            "oa_bias_-2_annual_direct_5min_working.csv": "oa_bias_-2",
            "coi_leakage_050_annual_direct_5min_working.csv": "coi_leakage_050", 
            "coi_stuck_075_annual_resampled_direct_5min_working.csv": "coi_stuck_075",
            "coi_stuck_025_annual_direct_5min_working.csv": "coi_stuck_025",
            "damper_stuck_075_annual_resampled_direct_5min_working.csv": "damper_stuck_075",
            "damper_stuck_025_annual_direct_5min_working.csv": "damper_stuck_025",
        }
        # self.file_label_map = {
        #     "AHU_annual_resampled_direct_5min_working.csv": "AHU_annual",
        # }
        
        # åˆ›å»ºæ ‡ç­¾æ˜ å°„
        unique_labels = sorted(set(self.file_label_map.values()))
        self.args.num_class = len(unique_labels)
        self.label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}
        self.idx_to_label = {idx: label for label, idx in self.label_to_idx.items()}
        
        print(f"æ ‡ç­¾æ˜ å°„: {self.label_to_idx}")
        
        # ç”ŸæˆæŒä¹…åŒ–æ–‡ä»¶è·¯å¾„
        file_keys = sorted(self.file_label_map.keys())
        file_str = "|".join(file_keys).encode()
        file_hash = hashlib.md5(file_str).hexdigest()
        self.persist_path = os.path.join(
            self.root_path,
            f"dual_gaf_data_win{self.win_size}_step{self.step}_files{len(self.file_label_map)}_{file_hash}_dtype{self.data_type_method}.pkl",
        )

        # åˆå§‹åŒ–æ•°æ®å­˜å‚¨
        self.train_summation = None
        self.train_difference = None
        self.train_time_series = None  # æ–°å¢ï¼šåŸå§‹æ—¶åºæ•°æ®
        self.train_labels = None
        self.val_summation = None
        self.val_difference = None
        self.val_time_series = None    # æ–°å¢ï¼šåŸå§‹æ—¶åºæ•°æ®
        self.val_labels = None
        self.scalers = None
        
        # åŠ è½½æˆ–å¤„ç†æ•°æ®
        if os.path.exists(self.persist_path):
            print(f"ğŸ“ æ£€æµ‹åˆ°å·²å­˜åœ¨çš„åŒGAFæŒä¹…åŒ–æ–‡ä»¶: {self.persist_path}")
            print(f"ğŸ’¾ ç›´æ¥åŠ è½½é¢„å¤„ç†æ•°æ®ï¼Œæ— éœ€å¤šè¿›ç¨‹å¤„ç†")
            self.load_persisted_data(self.persist_path)
        else:
            print(f"âš ï¸  æœªæ‰¾åˆ°æŒä¹…åŒ–æ–‡ä»¶ï¼Œå¼€å§‹æ•°æ®å¤„ç†...")
            self._process_data()
        
        self._initialized = True
        print(f"åŒGAFæ•°æ®ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"è®­ç»ƒé›†: {len(self.train_summation)} æ ·æœ¬")
        print(f"éªŒè¯é›†: {len(self.val_summation)} æ ·æœ¬")

    def _init_parallel_config(self):
        """å»¶è¿Ÿåˆå§‹åŒ–å¹¶è¡Œå¤„ç†é…ç½®ï¼ˆåªåœ¨éœ€è¦æ•°æ®å¤„ç†æ—¶è°ƒç”¨ï¼‰"""
        if self._parallel_initialized:
            return
            
        self.n_jobs = getattr(self.args, 'n_jobs', min(mp.cpu_count(), 8))  # é™åˆ¶æœ€å¤§è¿›ç¨‹æ•°
        self.use_multiprocessing = getattr(self.args, 'use_multiprocessing', True)
        self.chunk_size = getattr(self.args, 'chunk_size', 100)  # æ¯ä¸ªè¿›ç¨‹å¤„ç†çš„æ•°æ®å—å¤§å°
        self.use_shared_memory = getattr(self.args, 'use_shared_memory', True)  # å¯ç”¨å…±äº«å†…å­˜ä¼˜åŒ–
        
        print(f"ğŸš€ åˆå§‹åŒ–å¹¶è¡Œå¤„ç†é…ç½® - è¿›ç¨‹æ•°: {self.n_jobs}, ä½¿ç”¨å¤šè¿›ç¨‹: {self.use_multiprocessing}, å…±äº«å†…å­˜: {self.use_shared_memory}")
        self._parallel_initialized = True

    def _process_data(self):
        """å¤„ç†æ•°æ®çš„ä¸»è¦é€»è¾‘"""
        # ğŸš€ åªæœ‰åœ¨éœ€è¦å¤„ç†æ•°æ®æ—¶æ‰åˆå§‹åŒ–å¹¶è¡Œé…ç½®
        self._init_parallel_config()
        
        # å¢å¼ºå‹æ•°æ®åŠ è½½å™¨ï¼ˆå¤ç”¨åŸæœ‰é€»è¾‘ï¼‰
        def load_and_segment(path, rows=None, skip_normalize=True):
            exclude_columns = [
                "Datetime", "is_working", "ts", "date", "hour", "time_diff", "segment_id",
            ]

            if rows:
                df = pd.read_csv(path, nrows=rows)
            else:
                df = pd.read_csv(path)
            df["Datetime"] = pd.to_datetime(df["Datetime"])

            # ç”Ÿæˆæ—¶é—´åºåˆ—ç‰¹å¾
            df["ts"] = df["Datetime"].astype("int64") // 10**9
            df["date"] = df["Datetime"].dt.date
            df["hour"] = df["Datetime"].dt.hour

            # ä½¿ç”¨is_workingåˆ—è¿‡æ»¤å·¥ä½œæ—¶é—´
            df = df[df["is_working"] == 1]

            # åˆ†æ®µé€»è¾‘ï¼šè¿ç»­å·¥ä½œæ—¶é—´æ®µè¯†åˆ«
            df = df.sort_values("ts").reset_index(drop=True)
            df["time_diff"] = df["ts"].diff() > 3600 * 2
            df["segment_id"] = df["time_diff"].cumsum()

            # è·å–ç‰¹å¾åˆ—
            feature_columns = [
                col for col in df.columns
                if col not in [
                    "Datetime", "ts", "date", "hour", "time_diff", "segment_id", "is_working",
                    "SA_TEMPSPT", "SYS_CTL", "RF_SPD_DM", "SF_SPD_DM",
                ]
            ]

            # æå–æ‰€æœ‰å·¥ä½œæ—¶æ®µæ•°æ®
            segments = []
            for seg_id, group in df.groupby("segment_id"):
                if len(group) >= self.win_size:
                    segment_data = group[feature_columns].values
                    segments.append(segment_data)

            return segments, feature_columns

        # åˆ†æ®µçª—å£ç”Ÿæˆå™¨
        def create_segment_windows(segments):
            all_windows = []
            for seg in segments:
                if len(seg) == self.win_size:
                    all_windows.append(seg)
                else:
                    for i in range(0, len(seg) - self.win_size + 1, self.step):
                        all_windows.append(seg[i : i + self.win_size])
            return np.array(all_windows) if len(all_windows) > 0 else np.array([])



        # æ”¶é›†æ‰€æœ‰æ–‡ä»¶çš„æ•°æ®å’Œæ ‡ç­¾
        all_segments = []
        all_labels = []
        feature_columns = None

        print("\n=== å¼€å§‹åŠ è½½æ•°æ®æ–‡ä»¶ ===")
        for i, (file_name, label) in enumerate(self.file_label_map.items()):
            file_path = os.path.join(self.root_path, file_name)
            print(f"\nå¤„ç†æ–‡ä»¶ {i+1}/{len(self.file_label_map)}: {file_path}")
            print(f"æ ‡ç­¾å€¼: {label}")

            segments, cols = load_and_segment(file_path, None, True)

            if not segments:
                print(f"è­¦å‘Š: æ–‡ä»¶ {file_name} æœªåŒ…å«æœ‰æ•ˆæ•°æ®æ®µ")
                continue

            print(f"æˆåŠŸåŠ è½½ {len(segments)} ä¸ªæ•°æ®æ®µ")
            print(f"ç‰¹å¾åˆ—æ•°é‡: {len(cols)}")

            if feature_columns is None:
                feature_columns = cols
            elif set(feature_columns) != set(cols):
                print(f"è­¦å‘Š: æ–‡ä»¶ {file_name} çš„ç‰¹å¾åˆ—ä¸ä¹‹å‰ä¸åŒ¹é…")

            # ä¸ºæ¯ä¸ªæ®µæ·»åŠ å¯¹åº”æ ‡ç­¾
            numeric_label = self.label_to_idx[label]
            for segment in segments:
                all_segments.append(segment)
                all_labels.append(numeric_label)

        print(f"\n=== æ•°æ®åŠ è½½å®Œæˆ ===")
        print(f"æ€»æ•°æ®æ®µæ•°: {len(all_segments)}")

        # é€šé“çº§åˆ«å½’ä¸€åŒ– - ä½¿ç”¨å¹¶è¡Œå¤„ç†
        self.normalize_features_parallel(all_segments, feature_columns)

        # åˆ›å»ºçª—å£
        print("\n=== å¼€å§‹åˆ›å»ºæ—¶é—´çª—å£ ===")
        labeled_windows = []
        labeled_labels = []

        for seg_idx, (seg, label) in enumerate(zip(all_segments, all_labels)):
            if seg_idx % 100 == 0:
                print(f"å¤„ç†æ•°æ®æ®µ {seg_idx+1}/{len(all_segments)}")
            windows = create_segment_windows([seg])
            if len(windows) > 0:
                for window in windows:
                    labeled_windows.append(window)
                    labeled_labels.append(label)

        print(f"\n=== çª—å£åˆ›å»ºå®Œæˆ ===")
        print(f"ç”Ÿæˆçš„çª—å£æ•°é‡: {len(labeled_windows)}")

        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        labeled_windows = np.array(labeled_windows)
        labeled_labels = np.array(labeled_labels)

        if len(labeled_windows) == 0:
            raise ValueError("æœªèƒ½ç”Ÿæˆä»»ä½•æœ‰æ•ˆçš„æ—¶é—´çª—å£")

        # æ‰“ä¹±æ•°æ®
        print("\n=== æ‰“ä¹±æ•°æ® ===")
        np.random.seed(42)
        indices = np.random.permutation(len(labeled_windows))
        labeled_windows = labeled_windows[indices]
        labeled_labels = labeled_labels[indices]

        # åŒGAFè½¬æ¢
        print("\n=== å¼€å§‹åŒGAFè½¬æ¢ ===")
        print(f"è¾“å…¥æ•°æ®å½¢çŠ¶: {labeled_windows.shape}")
        
        start_time = time.time()
        print("è½¬æ¢Summation GAF...")
        gaf_summation_data = self.generate_gaf_matrix_shared_memory(labeled_windows, "summation", False)
        print(f"Summation GAFè½¬æ¢åæ•°æ®å½¢çŠ¶: {gaf_summation_data.shape}")
        summation_time = time.time() - start_time
        
        start_time = time.time()
        print("è½¬æ¢Difference GAF...")
        gaf_difference_data = self.generate_gaf_matrix_shared_memory(labeled_windows, "difference", False)
        print(f"Difference GAFè½¬æ¢åæ•°æ®å½¢çŠ¶: {gaf_difference_data.shape}")
        difference_time = time.time() - start_time
        
        print(f"GAFè½¬æ¢è€—æ—¶ - Summation: {summation_time:.2f}s, Difference: {difference_time:.2f}s")

        # æ•°æ®ç±»å‹è½¬æ¢
        print("\n=== å¼€å§‹æ•°æ®èŒƒå›´è½¬æ¢ï¼ˆSummation GAFï¼‰ ===")
        start_time = time.time()
        gaf_summation_data = self.convert_gaf_data_type_shared_memory(gaf_summation_data)
        summation_convert_time = time.time() - start_time
        
        print("\n=== å¼€å§‹æ•°æ®èŒƒå›´è½¬æ¢ï¼ˆDifference GAFï¼‰ ===")
        start_time = time.time()
        gaf_difference_data = self.convert_gaf_data_type_shared_memory(gaf_difference_data)
        difference_convert_time = time.time() - start_time
        
        print(f"æ•°æ®ç±»å‹è½¬æ¢è€—æ—¶ - Summation: {summation_convert_time:.2f}s, Difference: {difference_convert_time:.2f}s")

        print(f"Summation GAF æ•°æ®èŒƒå›´: [{gaf_summation_data.min()}, {gaf_summation_data.max()}]")
        print(f"Difference GAF æ•°æ®èŒƒå›´: [{gaf_difference_data.min()}, {gaf_difference_data.max()}]")

        # è®¡ç®—åˆ’åˆ†ç‚¹
        train_split = int(len(gaf_summation_data) * (1 - self.test_size))
        
        # åˆ’åˆ†æ•°æ®é›†
        self.train_summation = gaf_summation_data[:train_split]
        self.train_difference = gaf_difference_data[:train_split]
        self.train_time_series = labeled_windows[:train_split]  # ä¿å­˜åŸå§‹æ—¶åºæ•°æ®
        self.train_labels = labeled_labels[:train_split]
        
        self.val_summation = gaf_summation_data[train_split:]
        self.val_difference = gaf_difference_data[train_split:]
        self.val_time_series = labeled_windows[train_split:]    # ä¿å­˜åŸå§‹æ—¶åºæ•°æ®
        self.val_labels = labeled_labels[train_split:]

        print("\n=== æ•°æ®é›†åˆ’åˆ†å®Œæˆ ===")
        print(f"è®­ç»ƒé›†: {len(self.train_summation)} æ ·æœ¬")
        print(f"éªŒè¯é›†: {len(self.val_summation)} æ ·æœ¬")

        # æ•°æ®å¤„ç†å®Œæˆåè‡ªåŠ¨ä¿å­˜
        print("\n=== ä¿å­˜é¢„å¤„ç†æ•°æ® ===")
        self.persist_data(self.persist_path, labeled_windows, labeled_labels)
        print(f"å·²è‡ªåŠ¨ä¿å­˜é¢„å¤„ç†æ•°æ®åˆ°: {self.persist_path}")

    def generate_gaf_matrix_shared_memory(self, data: np.ndarray, method: str = "summation", normalize: bool = False) -> np.ndarray:
        """ä½¿ç”¨å…±äº«å†…å­˜çš„é«˜æ•ˆå¹¶è¡ŒGAFçŸ©é˜µç”Ÿæˆå‡½æ•°"""
        if data.ndim != 3:
            raise ValueError(f"è¾“å…¥æ•°æ®å¿…é¡»ä¸º3ç»´ï¼Œå½“å‰ç»´åº¦æ•°ï¼š{data.ndim}ï¼Œæ­£ç¡®å½¢çŠ¶åº”ä¸º[N, T, D]")

        N, T, D = data.shape
        valid_methods = {"summation", "difference"}
        if method not in valid_methods:
            raise ValueError(f"methodå¿…é¡»ä¸º{sorted(valid_methods)}ä¹‹ä¸€ï¼Œå½“å‰è¾“å…¥ï¼š{method}")

        # è®¡ç®—æ•°æ®å¤æ‚åº¦å’Œå†…å­˜ä½¿ç”¨
        data_size_gb = data.nbytes / (1024**3)
        estimated_output_size_gb = N * D * T * T * 4 / (1024**3)  # float32
        
        print(f"å¼€å§‹å…±äº«å†…å­˜GAFè½¬æ¢ - æ–¹æ³•: {method}, æ•°æ®é‡: {N}")
        print(f"è¾“å…¥å¤§å°: {data_size_gb:.2f}GB, é¢„ä¼°è¾“å‡ºå¤§å°: {estimated_output_size_gb:.2f}GB")
        
        # æ™ºèƒ½å†³ç­–ï¼šæ˜¯å¦ä½¿ç”¨å…±äº«å†…å­˜å¹¶è¡Œ
        min_samples_for_shared_memory = 800   # é€‚ä¸­çš„é˜ˆå€¼
        max_memory_gb = 20  # é€‚åº”å¤§å†…å­˜æœåŠ¡å™¨
        
        if (N < min_samples_for_shared_memory or 
            not self.use_multiprocessing or 
            not self.use_shared_memory or
            estimated_output_size_gb > max_memory_gb):
            
            print(f"ä½¿ç”¨æ ‡å‡†å¹¶è¡Œå¤„ç† - æ•°æ®é‡: {N}, è¾“å‡ºå¤§å°: {estimated_output_size_gb:.2f}GB")
            return self.generate_gaf_matrix_parallel(data, method, normalize)
        
        try:
            # åˆ›å»ºè¾“å…¥æ•°æ®çš„å…±äº«å†…å­˜
            input_shm = shared_memory.SharedMemory(create=True, size=data.nbytes)
            input_array = np.ndarray(data.shape, dtype=data.dtype, buffer=input_shm.buf)
            input_array[:] = data[:]
            
            # åˆ›å»ºç»“æœæ•°ç»„çš„å…±äº«å†…å­˜
            result_shape = (N, D, T, T)
            result_dtype = np.float32
            result_size = N * D * T * T * np.dtype(result_dtype).itemsize
            result_shm = shared_memory.SharedMemory(create=True, size=result_size)
            result_array = np.ndarray(result_shape, dtype=result_dtype, buffer=result_shm.buf)
            
            print(f"åˆ›å»ºå…±äº«å†…å­˜ - è¾“å…¥: {input_shm.name}, ç»“æœ: {result_shm.name}")
            
            # æ™ºèƒ½è®¡ç®—æœ€ä¼˜å—å¤§å°å’Œè¿›ç¨‹æ•°
            memory_per_gb = max(1, int(estimated_output_size_gb))
            base_chunk_size = max(self.chunk_size, 400)  # æé«˜åŸºç¡€å—å¤§å°
            
            # æ ¹æ®æ•°æ®å¤§å°åŠ¨æ€è°ƒæ•´
            if estimated_output_size_gb > 10:
                # å¤§æ•°æ®é›†ï¼šå¢å¤§å—å‡å°‘é€šä¿¡å¼€é”€
                optimal_chunk_size = max(base_chunk_size, N // (self.n_jobs * 1.5))
            else:
                # ä¸­ç­‰æ•°æ®é›†ï¼šå¹³è¡¡å¹¶è¡Œåº¦å’Œå¼€é”€
                optimal_chunk_size = max(base_chunk_size, N // (self.n_jobs * 2))
            
            # ç¡®ä¿æ¯ä¸ªå—è¶³å¤Ÿå¤§ä»¥æ‘Šé”€å…±äº«å†…å­˜å¼€é”€
            optimal_chunk_size = max(optimal_chunk_size, 300)
            
            # è®¡ç®—å®é™…éœ€è¦çš„å—æ•°
            num_chunks = max(1, (N + optimal_chunk_size - 1) // optimal_chunk_size)
            
            # å…³é”®ä¼˜åŒ–ï¼šè°ƒæ•´è¿›ç¨‹æ•°ä»¥åŒ¹é…å®é™…å—æ•°
            effective_n_jobs = min(self.n_jobs, num_chunks, N // 100)  # è‡³å°‘100æ ·æœ¬/è¿›ç¨‹
            effective_n_jobs = max(effective_n_jobs, 1)  # è‡³å°‘1ä¸ªè¿›ç¨‹
            
            # é‡æ–°è®¡ç®—æœ€ä¼˜å—å¤§å°
            if effective_n_jobs < self.n_jobs:
                optimal_chunk_size = max(N // effective_n_jobs, 300)
            
            chunk_indices = []
            for i in range(0, N, optimal_chunk_size):
                end_idx = min(i + optimal_chunk_size, N)
                chunk_indices.append((i, end_idx))
            
            print(f"æ™ºèƒ½è°ƒæ•´è¿›ç¨‹é…ç½®:")
            print(f"  åŸå§‹è¿›ç¨‹æ•°: {self.n_jobs} -> æœ‰æ•ˆè¿›ç¨‹æ•°: {effective_n_jobs}")
            print(f"  åŸå§‹å—å¤§å°: {self.chunk_size} -> ä¼˜åŒ–å—å¤§å°: {optimal_chunk_size}")
            print(f"  å®é™…å—æ•°: {len(chunk_indices)}, æ•°æ®å¤§å°: {estimated_output_size_gb:.1f}GB")
            
            # å¦‚æœåªæœ‰1ä¸ªå—æˆ–è¿›ç¨‹æ•°ä¸º1ï¼Œè€ƒè™‘ä½¿ç”¨å•è¿›ç¨‹
            if len(chunk_indices) == 1 or effective_n_jobs == 1:
                print("å—æ•°å¤ªå°‘ï¼Œä½¿ç”¨å•è¿›ç¨‹å¤„ç†é¿å…å¤šè¿›ç¨‹å¼€é”€")
                input_shm.close()
                input_shm.unlink()
                result_shm.close()
                result_shm.unlink()
                return self._generate_gaf_matrix_single(data, method, normalize)
            
            # å¹¶è¡Œå¤„ç†
            with ProcessPoolExecutor(max_workers=effective_n_jobs) as executor:
                futures = []
                for start_idx, end_idx in chunk_indices:
                    future = executor.submit(
                        self._process_gaf_chunk_shared_memory,
                        input_shm.name,
                        data.shape,
                        data.dtype,
                        start_idx,
                        end_idx,
                        method,
                        normalize,
                        result_shm.name,
                        result_shape,
                        result_dtype
                    )
                    futures.append(future)
                
                # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                completed = 0
                for future in as_completed(futures):
                    try:
                        future.result()
                        completed += 1
                        if completed % max(1, len(futures) // 5) == 0:
                            print(f"å…±äº«å†…å­˜GAFå¤„ç†è¿›åº¦: {completed}/{len(futures)} ({100*completed/len(futures):.1f}%)")
                    except Exception as exc:
                        print(f'å…±äº«å†…å­˜GAFå¤„ç†å¼‚å¸¸: {exc}')
                        raise exc
            
            # å¤åˆ¶ç»“æœå¹¶æ¸…ç†å…±äº«å†…å­˜
            final_result = result_array.copy()
            
            # æ¸…ç†å…±äº«å†…å­˜
            input_shm.close()
            input_shm.unlink()
            result_shm.close()
            result_shm.unlink()
            
            print(f"å…±äº«å†…å­˜GAFè½¬æ¢å®Œæˆï¼Œæœ€ç»ˆå½¢çŠ¶: {final_result.shape}")
            return final_result
            
        except Exception as e:
            print(f"å…±äº«å†…å­˜GAFå¤„ç†å¤±è´¥: {e}")
            print("å›é€€åˆ°æ ‡å‡†å¹¶è¡Œå¤„ç†")
            
            # æ¸…ç†å¯èƒ½çš„å…±äº«å†…å­˜
            try:
                if 'input_shm' in locals():
                    input_shm.close()
                    input_shm.unlink()
                if 'result_shm' in locals():
                    result_shm.close()
                    result_shm.unlink()
            except:
                pass
            
            # å›é€€åˆ°æ ‡å‡†æ–¹æ³•
            return self.generate_gaf_matrix_parallel(data, method, normalize)

    def generate_gaf_matrix_parallel(self, data: np.ndarray, method: str = "summation", normalize: bool = False) -> np.ndarray:
        """å¹¶è¡ŒGAFçŸ©é˜µç”Ÿæˆå‡½æ•°"""
        if data.ndim != 3:
            raise ValueError(f"è¾“å…¥æ•°æ®å¿…é¡»ä¸º3ç»´ï¼Œå½“å‰ç»´åº¦æ•°ï¼š{data.ndim}ï¼Œæ­£ç¡®å½¢çŠ¶åº”ä¸º[N, T, D]")

        N, T, D = data.shape
        valid_methods = {"summation", "difference"}
        if method not in valid_methods:
            raise ValueError(f"methodå¿…é¡»ä¸º{sorted(valid_methods)}ä¹‹ä¸€ï¼Œå½“å‰è¾“å…¥ï¼š{method}")

        print(f"å¼€å§‹å¹¶è¡ŒGAFè½¬æ¢ - æ–¹æ³•: {method}, æ•°æ®é‡: {N}")
        
        # æ™ºèƒ½å†³ç­–ï¼šæ˜¯å¦ä½¿ç”¨å¤šè¿›ç¨‹
        min_samples_for_multiprocess = 200  # æœ€å°æ ·æœ¬æ•°é˜ˆå€¼
        min_samples_per_process = 100       # æ¯ä¸ªè¿›ç¨‹æœ€å°‘å¤„ç†çš„æ ·æœ¬æ•°
        
        # å¦‚æœæ•°æ®é‡è¾ƒå°æˆ–ç¦ç”¨å¤šè¿›ç¨‹ï¼Œç›´æ¥ä½¿ç”¨å•è¿›ç¨‹
        if N < min_samples_for_multiprocess or not self.use_multiprocessing:
            print(f"æ•°æ®é‡è¾ƒå°({N} < {min_samples_for_multiprocess})æˆ–ç¦ç”¨å¤šè¿›ç¨‹ï¼Œä½¿ç”¨å•è¿›ç¨‹å¤„ç†")
            return self._generate_gaf_matrix_single(data, method, normalize)
        
        # è®¡ç®—æœ‰æ•ˆè¿›ç¨‹æ•°ï¼šç¡®ä¿æ¯ä¸ªè¿›ç¨‹æœ‰è¶³å¤Ÿå·¥ä½œé‡
        max_useful_processes = max(1, N // min_samples_per_process)
        effective_n_jobs = min(self.n_jobs, max_useful_processes)
        
        # é‡æ–°è®¡ç®—å—å¤§å°ä»¥å……åˆ†åˆ©ç”¨è¿›ç¨‹
        optimal_chunk_size = max(N // effective_n_jobs, min_samples_per_process)
        
        # åˆ†å—å¤„ç†
        chunks = self._split_data_into_chunks(data, optimal_chunk_size)
        actual_chunks = len(chunks)
        
        # å†æ¬¡è°ƒæ•´è¿›ç¨‹æ•°ä»¥åŒ¹é…å®é™…å—æ•°
        final_n_jobs = min(effective_n_jobs, actual_chunks)
        
        print(f"æ™ºèƒ½å¹¶è¡Œé…ç½®:")
        print(f"  æ•°æ®é‡: {N}, æœ€å°æ¯è¿›ç¨‹æ ·æœ¬: {min_samples_per_process}")
        print(f"  åŸå§‹è¿›ç¨‹æ•°: {self.n_jobs} -> æœ‰æ•ˆè¿›ç¨‹æ•°: {effective_n_jobs} -> æœ€ç»ˆè¿›ç¨‹æ•°: {final_n_jobs}")
        print(f"  å—å¤§å°: {optimal_chunk_size}, å®é™…å—æ•°: {actual_chunks}")
        
        # å¦‚æœæœ€ç»ˆåªéœ€è¦1ä¸ªè¿›ç¨‹ï¼Œç›´æ¥ä½¿ç”¨å•è¿›ç¨‹é¿å…å¤šè¿›ç¨‹å¼€é”€
        if final_n_jobs == 1:
            print("ä¼˜åŒ–ååªéœ€1ä¸ªè¿›ç¨‹ï¼Œä½¿ç”¨å•è¿›ç¨‹é¿å…å¤šè¿›ç¨‹å¼€é”€")
            return self._generate_gaf_matrix_single(data, method, normalize)
        
        # ä½¿ç”¨ProcessPoolExecutorè¿›è¡Œå¹¶è¡Œå¤„ç†
        results = []
        with ProcessPoolExecutor(max_workers=final_n_jobs) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_idx = {
                executor.submit(self._process_gaf_chunk, chunk, method, normalize): i 
                for i, chunk in enumerate(chunks)
            }
            
            # æ”¶é›†ç»“æœ
            chunk_results = [None] * len(chunks)
            for future in as_completed(future_to_idx):
                idx = future_to_idx[future]
                try:
                    chunk_results[idx] = future.result()
                    print(f"å®Œæˆç¬¬ {idx+1}/{len(chunks)} å—çš„GAFè½¬æ¢")
                except Exception as exc:
                    print(f'å— {idx} ç”Ÿæˆå¼‚å¸¸: {exc}')
                    raise exc
        
        # åˆå¹¶ç»“æœ
        print("åˆå¹¶æ‰€æœ‰å—çš„ç»“æœ...")
        final_result = np.concatenate(chunk_results, axis=0)
        print(f"å¹¶è¡ŒGAFè½¬æ¢å®Œæˆï¼Œæœ€ç»ˆå½¢çŠ¶: {final_result.shape}")
        return final_result

    def _generate_gaf_matrix_single(self, data: np.ndarray, method: str = "summation", normalize: bool = False) -> np.ndarray:
        """å•è¿›ç¨‹GAFçŸ©é˜µç”Ÿæˆå‡½æ•°"""
        N, T, D = data.shape
        transposed_data = data.transpose(0, 2, 1)
        flattened_data = transposed_data.reshape(-1, T)
        gasf = GramianAngularField(method=method)
        batch_gaf = gasf.fit_transform(flattened_data)
        reshaped_gaf = batch_gaf.reshape(N, D, T, T)
        return reshaped_gaf.astype(np.float32)

    @staticmethod
    def _process_gaf_chunk(chunk_data: np.ndarray, method: str, normalize: bool) -> np.ndarray:
        """å¤„ç†å•ä¸ªæ•°æ®å—çš„GAFè½¬æ¢ï¼ˆé™æ€æ–¹æ³•ï¼Œæ”¯æŒå¤šè¿›ç¨‹ï¼‰"""
        N, T, D = chunk_data.shape
        transposed_data = chunk_data.transpose(0, 2, 1)
        flattened_data = transposed_data.reshape(-1, T)
        gasf = GramianAngularField(method=method)
        batch_gaf = gasf.fit_transform(flattened_data)
        reshaped_gaf = batch_gaf.reshape(N, D, T, T)
        return reshaped_gaf.astype(np.float32)

    @staticmethod
    def _process_gaf_chunk_shared_memory(shm_name: str, shape: tuple, dtype, 
                                        start_idx: int, end_idx: int, 
                                        method: str, normalize: bool,
                                        result_shm_name: str, result_shape: tuple, result_dtype) -> None:
        """ä½¿ç”¨å…±äº«å†…å­˜å¤„ç†GAFè½¬æ¢å—ï¼ˆé™æ€æ–¹æ³•ï¼Œæ”¯æŒå¤šè¿›ç¨‹ï¼‰"""
        try:
            # è¿æ¥åˆ°è¾“å…¥å…±äº«å†…å­˜
            existing_shm = shared_memory.SharedMemory(name=shm_name)
            input_array = np.ndarray(shape, dtype=dtype, buffer=existing_shm.buf)
            
            # æå–å½“å‰å—çš„æ•°æ®
            chunk_data = input_array[start_idx:end_idx].copy()  # å¤åˆ¶é¿å…å…±äº«å†…å­˜ç«äº‰
            existing_shm.close()  # ç«‹å³å…³é—­è¾“å…¥å…±äº«å†…å­˜è¿æ¥
            
            # GAFè½¬æ¢
            N, T, D = chunk_data.shape
            transposed_data = chunk_data.transpose(0, 2, 1)
            flattened_data = transposed_data.reshape(-1, T)
            gasf = GramianAngularField(method=method)
            batch_gaf = gasf.fit_transform(flattened_data)
            reshaped_gaf = batch_gaf.reshape(N, D, T, T).astype(np.float32)
            
            # å°†ç»“æœå†™å…¥ç»“æœå…±äº«å†…å­˜
            result_shm = shared_memory.SharedMemory(name=result_shm_name)
            result_array = np.ndarray(result_shape, dtype=result_dtype, buffer=result_shm.buf)
            
            # è®¡ç®—åœ¨ç»“æœæ•°ç»„ä¸­çš„ä½ç½®
            result_start = start_idx
            result_end = start_idx + reshaped_gaf.shape[0]
            result_array[result_start:result_end] = reshaped_gaf
            
            result_shm.close()
            
        except Exception as e:
            print(f"å…±äº«å†…å­˜GAFå¤„ç†é”™è¯¯: {e}")
            raise

    def _split_data_into_chunks(self, data: np.ndarray, chunk_size: int) -> list:
        """å°†æ•°æ®åˆ†å‰²æˆå—"""
        N = data.shape[0]
        chunks = []
        for i in range(0, N, chunk_size):
            end_idx = min(i + chunk_size, N)
            chunks.append(data[i:end_idx])
        return chunks

    def convert_gaf_data_type_parallel(self, data: np.ndarray) -> np.ndarray:
        """å¹¶è¡ŒGAFæ•°æ®ç±»å‹è½¬æ¢"""
        print(f"å¼€å§‹å¹¶è¡Œæ•°æ®ç±»å‹è½¬æ¢ï¼Œæ•°æ®å½¢çŠ¶: {data.shape}, å†…å­˜å ç”¨: {data.nbytes / 1024**3:.2f} GB")
        
        if self.data_type_method == 'float32':
            return self._gaf_to_float32_parallel(data)
        elif self.data_type_method == 'uint8':
            return self._gaf_to_int_parallel(data, dtype=np.uint8)
        elif self.data_type_method == 'uint16':
            return self._gaf_to_int_parallel(data, dtype=np.uint16)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®ç±»å‹æ–¹æ³•: {self.data_type_method}")

    def _gaf_to_float32_parallel(self, data: np.ndarray) -> np.ndarray:
        """å¹¶è¡ŒFloat32è½¬æ¢æ–¹æ³•"""
        N = data.shape[0]
        
        # å¦‚æœæ•°æ®é‡è¾ƒå°ï¼Œä½¿ç”¨å•è¿›ç¨‹
        if N < self.chunk_size * 2 or not self.use_multiprocessing:
            print("æ•°æ®é‡è¾ƒå°æˆ–ç¦ç”¨å¤šè¿›ç¨‹ï¼Œä½¿ç”¨å•è¿›ç¨‹å¤„ç†")
            return self._gaf_to_float32(data)
        
        # åˆ†å—å¹¶è¡Œå¤„ç†
        chunks = self._split_data_into_chunks(data, self.chunk_size)
        print(f"ä½¿ç”¨å¹¶è¡Œå¤„ç†ï¼Œåˆ†ä¸º {len(chunks)} ä¸ªå—")
        
        results = []
        with ThreadPoolExecutor(max_workers=self.n_jobs) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_idx = {
                executor.submit(self._process_batch_float32, chunk): i 
                for i, chunk in enumerate(chunks)
            }
            
            # æ”¶é›†ç»“æœ
            chunk_results = [None] * len(chunks)
            for future in as_completed(future_to_idx):
                idx = future_to_idx[future]
                try:
                    chunk_results[idx] = future.result()
                    print(f"å®Œæˆç¬¬ {idx+1}/{len(chunks)} å—çš„Float32è½¬æ¢")
                except Exception as exc:
                    print(f'å— {idx} è½¬æ¢å¼‚å¸¸: {exc}')
                    raise exc
        
        return np.concatenate(chunk_results, axis=0)

    def _gaf_to_int_parallel(self, data: np.ndarray, dtype=np.uint8) -> np.ndarray:
        """å¹¶è¡Œæ•´æ•°è½¬æ¢æ–¹æ³•"""
        if dtype == np.uint8:
            max_val = 255
        elif dtype == np.uint16:
            max_val = 65535
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {dtype}")
        
        N = data.shape[0]
        
        # å¦‚æœæ•°æ®é‡è¾ƒå°ï¼Œä½¿ç”¨å•è¿›ç¨‹
        if N < self.chunk_size * 2 or not self.use_multiprocessing:
            print("æ•°æ®é‡è¾ƒå°æˆ–ç¦ç”¨å¤šè¿›ç¨‹ï¼Œä½¿ç”¨å•è¿›ç¨‹å¤„ç†")
            return self._gaf_to_int(data, dtype)
        
        # åˆ†å—å¹¶è¡Œå¤„ç†
        chunks = self._split_data_into_chunks(data, self.chunk_size)
        print(f"ä½¿ç”¨å¹¶è¡Œå¤„ç†ï¼Œåˆ†ä¸º {len(chunks)} ä¸ªå—")
        
        # åˆ›å»ºéƒ¨åˆ†å‡½æ•°
        process_func = partial(self._process_batch_int, dtype=dtype, max_val=max_val)
        
        results = []
        with ThreadPoolExecutor(max_workers=self.n_jobs) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_idx = {
                executor.submit(process_func, chunk): i 
                for i, chunk in enumerate(chunks)
            }
            
            # æ”¶é›†ç»“æœ
            chunk_results = [None] * len(chunks)
            for future in as_completed(future_to_idx):
                idx = future_to_idx[future]
                try:
                    chunk_results[idx] = future.result()
                    print(f"å®Œæˆç¬¬ {idx+1}/{len(chunks)} å—çš„{dtype.__name__}è½¬æ¢")
                except Exception as exc:
                    print(f'å— {idx} è½¬æ¢å¼‚å¸¸: {exc}')
                    raise exc
        
        return np.concatenate(chunk_results, axis=0)

    @staticmethod
    def _process_conversion_chunk_shared_memory(input_shm_name: str, input_shape: tuple, input_dtype,
                                              result_shm_name: str, result_shape: tuple, result_dtype,
                                              start_idx: int, end_idx: int, target_dtype, max_val: int) -> None:
        """ä½¿ç”¨å…±äº«å†…å­˜å¤„ç†æ•°æ®è½¬æ¢å—"""
        try:
            # è¿æ¥åˆ°è¾“å…¥å…±äº«å†…å­˜
            input_shm = shared_memory.SharedMemory(name=input_shm_name)
            input_array = np.ndarray(input_shape, dtype=input_dtype, buffer=input_shm.buf)
            
            # æå–å—æ•°æ®
            chunk_data = input_array[start_idx:end_idx].copy()
            input_shm.close()
            
            # æ•°æ®è½¬æ¢
            data_min, data_max = chunk_data.min(), chunk_data.max()
            if data_min >= -1.0 and data_max <= 1.0:
                normalized = (chunk_data.astype(np.float64) + 1.0) * (max_val / 2.0)
            else:
                clipped = np.clip(chunk_data, -1, 1)
                normalized = (clipped.astype(np.float64) + 1.0) * (max_val / 2.0)
            
            converted_data = np.round(normalized).astype(target_dtype)
            
            # å†™å…¥ç»“æœå…±äº«å†…å­˜
            result_shm = shared_memory.SharedMemory(name=result_shm_name)
            result_array = np.ndarray(result_shape, dtype=result_dtype, buffer=result_shm.buf)
            result_array[start_idx:end_idx] = converted_data
            result_shm.close()
            
        except Exception as e:
            print(f"å…±äº«å†…å­˜è½¬æ¢å¤„ç†é”™è¯¯: {e}")
            raise

    def convert_gaf_data_type_shared_memory(self, data: np.ndarray) -> np.ndarray:
        """ä½¿ç”¨å…±äº«å†…å­˜çš„å¹¶è¡ŒGAFæ•°æ®ç±»å‹è½¬æ¢"""
        print(f"å¼€å§‹å…±äº«å†…å­˜æ•°æ®ç±»å‹è½¬æ¢ï¼Œæ•°æ®å½¢çŠ¶: {data.shape}, å†…å­˜å ç”¨: {data.nbytes / 1024**3:.2f} GB")
        
        N = data.shape[0]
        data_size_gb = data.nbytes / (1024**3)
        
        # ç›®æ ‡æ•°æ®ç±»å‹é…ç½®
        if self.data_type_method == 'float32':
            return self._gaf_to_float32_parallel(data)
        elif self.data_type_method == 'uint8':
            target_dtype = np.uint8
            max_val = 255
        elif self.data_type_method == 'uint16':
            target_dtype = np.uint16
            max_val = 65535
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®ç±»å‹æ–¹æ³•: {self.data_type_method}")
        
        # å†³ç­–ï¼šæ˜¯å¦ä½¿ç”¨å…±äº«å†…å­˜
        # æ•°æ®è½¬æ¢é€šå¸¸ä¸é€‚åˆå…±äº«å†…å­˜ï¼ˆå†…å­˜è®¿é—®å¯†é›†å‹vsè®¡ç®—å¯†é›†å‹ï¼‰
        min_samples_for_shared_memory = 2000  # æé«˜é˜ˆå€¼ï¼Œå‡å°‘å…±äº«å†…å­˜ä½¿ç”¨
        max_memory_gb = 15  # æé«˜å†…å­˜é™åˆ¶
        
        # å¯¹äºæ•°æ®è½¬æ¢ï¼Œå…±äº«å†…å­˜å¾€å¾€ä¸å¦‚å¤šçº¿ç¨‹é«˜æ•ˆ
        # å› ä¸ºè½¬æ¢æ˜¯å†…å­˜è®¿é—®å¯†é›†å‹è€Œéè®¡ç®—å¯†é›†å‹
        if (N < min_samples_for_shared_memory or 
            not self.use_multiprocessing or 
            not self.use_shared_memory or
            data_size_gb > max_memory_gb or
            data_size_gb < 2.0):  # å°äº2GBçš„æ•°æ®ä¸ä½¿ç”¨å…±äº«å†…å­˜
            print(f"ä½¿ç”¨æ ‡å‡†å¹¶è¡Œè½¬æ¢ - æ•°æ®é‡: {N}, å¤§å°: {data_size_gb:.2f}GB")
            print("  åŸå› : æ•°æ®è½¬æ¢ä¸ºå†…å­˜è®¿é—®å¯†é›†å‹ï¼Œå¤šçº¿ç¨‹æ›´é«˜æ•ˆ")
            return self._gaf_to_int_parallel(data, dtype=target_dtype)
        
        try:
            # åˆ›å»ºè¾“å…¥æ•°æ®å…±äº«å†…å­˜
            input_shm = shared_memory.SharedMemory(create=True, size=data.nbytes)
            input_array = np.ndarray(data.shape, dtype=data.dtype, buffer=input_shm.buf)
            input_array[:] = data[:]
            
            # åˆ›å»ºç»“æœæ•°æ®å…±äº«å†…å­˜
            result_size = data.size * np.dtype(target_dtype).itemsize
            result_shm = shared_memory.SharedMemory(create=True, size=result_size)
            result_array = np.ndarray(data.shape, dtype=target_dtype, buffer=result_shm.buf)
            
            print(f"åˆ›å»ºè½¬æ¢å…±äº«å†…å­˜ - è¾“å…¥: {input_shm.name}, ç»“æœ: {result_shm.name}")
            
            # ä¼˜åŒ–çº¿ç¨‹æ•°å’Œå—å¤§å°
            optimal_workers = min(self.n_jobs, 6)  # è½¬æ¢ä»»åŠ¡é™åˆ¶çº¿ç¨‹æ•°
            optimal_chunk_size = max(N // (optimal_workers * 2), 200)
            
            # è®¡ç®—å—åˆ†å‰²
            chunk_indices = []
            for i in range(0, N, optimal_chunk_size):
                end_idx = min(i + optimal_chunk_size, N)
                chunk_indices.append((i, end_idx))
            
            print(f"ä½¿ç”¨{optimal_workers}ä¸ªçº¿ç¨‹å¤„ç†{len(chunk_indices)}ä¸ªå—ï¼Œå—å¤§å°çº¦{optimal_chunk_size}")
            
            # å¹¶è¡Œå¤„ç†
            with ThreadPoolExecutor(max_workers=optimal_workers) as executor:
                futures = []
                for start_idx, end_idx in chunk_indices:
                    future = executor.submit(
                        self._process_conversion_chunk_shared_memory,
                        input_shm.name,
                        data.shape,
                        data.dtype,
                        result_shm.name,
                        data.shape,
                        target_dtype,
                        start_idx,
                        end_idx,
                        target_dtype,
                        max_val
                    )
                    futures.append(future)
                
                # ç­‰å¾…å®Œæˆ
                completed = 0
                for future in as_completed(futures):
                    try:
                        future.result()
                        completed += 1
                        if completed % max(1, len(futures) // 3) == 0:
                            print(f"å…±äº«å†…å­˜è½¬æ¢è¿›åº¦: {completed}/{len(futures)} ({100*completed/len(futures):.1f}%)")
                    except Exception as exc:
                        print(f'å…±äº«å†…å­˜è½¬æ¢å¼‚å¸¸: {exc}')
                        raise exc
            
            # å¤åˆ¶ç»“æœ
            final_result = result_array.copy()
            
            # æ¸…ç†å…±äº«å†…å­˜
            input_shm.close()
            input_shm.unlink()
            result_shm.close()
            result_shm.unlink()
            
            print(f"å…±äº«å†…å­˜è½¬æ¢å®Œæˆï¼Œè¾“å‡ºç±»å‹: {final_result.dtype}, å¤§å°: {final_result.nbytes / 1024**3:.2f}GB")
            return final_result
            
        except Exception as e:
            print(f"å…±äº«å†…å­˜è½¬æ¢å¤±è´¥: {e}")
            print("å›é€€åˆ°æ ‡å‡†å¹¶è¡Œè½¬æ¢")
            
            # æ¸…ç†å…±äº«å†…å­˜
            try:
                if 'input_shm' in locals():
                    input_shm.close()
                    input_shm.unlink()
                if 'result_shm' in locals():
                    result_shm.close()
                    result_shm.unlink()
            except:
                pass
            
            return self._gaf_to_int_parallel(data, dtype=target_dtype)

    def normalize_features_parallel(self, all_segments: list, feature_columns: list) -> None:
        """å¹¶è¡Œç‰¹å¾å½’ä¸€åŒ–å¤„ç†"""
        print("\n=== å¼€å§‹å¹¶è¡Œç‰¹å¾å½’ä¸€åŒ– ===")
        start_time = time.time()
        
        # åˆå§‹åŒ–scalers
        self.scalers = {}
        
        if self.use_multiprocessing and len(feature_columns) > 1:
            print(f"ä½¿ç”¨å¹¶è¡Œå¤„ç† {len(feature_columns)} ä¸ªç‰¹å¾çš„å½’ä¸€åŒ–")
            
            # ä¸ºæ¯ä¸ªç‰¹å¾æ”¶é›†æ•°æ®å¹¶fit scaler
            with ThreadPoolExecutor(max_workers=min(self.n_jobs, len(feature_columns))) as executor:
                future_to_col = {}
                for i, col in enumerate(feature_columns):
                    feature_data = np.concatenate(
                        [seg[:, i].reshape(-1, 1) for seg in all_segments], axis=0
                    )
                    future = executor.submit(self._fit_scaler, col, feature_data)
                    future_to_col[future] = (i, col)
                
                # æ”¶é›†ç»“æœ
                for future in as_completed(future_to_col):
                    i, col = future_to_col[future]
                    try:
                        self.scalers[col] = future.result()
                        if i % 5 == 0:
                            print(f"å®Œæˆç‰¹å¾ {i+1}/{len(feature_columns)}: {col} çš„scalerè®­ç»ƒ")
                    except Exception as exc:
                        print(f'ç‰¹å¾ {col} scalerè®­ç»ƒå¼‚å¸¸: {exc}')
                        raise exc
            
            # å¹¶è¡Œåº”ç”¨å½’ä¸€åŒ–
            print("åº”ç”¨å½’ä¸€åŒ–åˆ°æ‰€æœ‰æ•°æ®æ®µ...")
            with ThreadPoolExecutor(max_workers=self.n_jobs) as executor:
                # åˆ†å—å¤„ç†æ•°æ®æ®µ
                segment_chunks = self._split_segments_into_chunks(all_segments, 50)  # æ¯ä¸ªçº¿ç¨‹å¤„ç†50ä¸ªæ•°æ®æ®µ
                
                future_to_idx = {}
                for chunk_idx, segment_chunk in enumerate(segment_chunks):
                    future = executor.submit(self._apply_normalization_to_chunk, segment_chunk, feature_columns)
                    future_to_idx[future] = chunk_idx
                
                # æ”¶é›†ç»“æœ
                normalized_chunks = [None] * len(segment_chunks)
                for future in as_completed(future_to_idx):
                    chunk_idx = future_to_idx[future]
                    try:
                        normalized_chunks[chunk_idx] = future.result()
                        print(f"å®Œæˆç¬¬ {chunk_idx+1}/{len(segment_chunks)} æ‰¹æ•°æ®æ®µçš„å½’ä¸€åŒ–")
                    except Exception as exc:
                        print(f'æ•°æ®æ®µæ‰¹æ¬¡ {chunk_idx} å½’ä¸€åŒ–å¼‚å¸¸: {exc}')
                        raise exc
                
                # åˆå¹¶ç»“æœ
                all_segments[:] = []  # æ¸…ç©ºåŸåˆ—è¡¨
                for chunk in normalized_chunks:
                    all_segments.extend(chunk)
        else:
            # å•è¿›ç¨‹å¤„ç†ï¼ˆåŸå§‹é€»è¾‘ï¼‰
            print("ä½¿ç”¨å•è¿›ç¨‹è¿›è¡Œç‰¹å¾å½’ä¸€åŒ–")
            for i, col in enumerate(feature_columns):
                if i % 5 == 0:
                    print(f"å¤„ç†ç‰¹å¾ {i+1}/{len(feature_columns)}: {col}")
                self.scalers[col] = MinMaxScaler(feature_range=(-1, 1))
                feature_data = np.concatenate(
                    [seg[:, i].reshape(-1, 1) for seg in all_segments], axis=0
                )
                self.scalers[col].fit(feature_data)
            
            # åº”ç”¨å½’ä¸€åŒ–
            for seg_idx in range(len(all_segments)):
                if seg_idx % 500 == 0:
                    print(f"å¤„ç†æ•°æ®æ®µ {seg_idx+1}/{len(all_segments)}")
                for i, col in enumerate(feature_columns):
                    all_segments[seg_idx][:, i] = (
                        self.scalers[col]
                        .transform(all_segments[seg_idx][:, i].reshape(-1, 1))
                        .flatten()
                    )
        
        normalize_time = time.time() - start_time
        print(f"ç‰¹å¾å½’ä¸€åŒ–å®Œæˆï¼Œè€—æ—¶: {normalize_time:.2f}s")

    @staticmethod
    def _fit_scaler(col_name: str, feature_data: np.ndarray) -> MinMaxScaler:
        """è®­ç»ƒå•ä¸ªç‰¹å¾çš„scalerï¼ˆé™æ€æ–¹æ³•ï¼Œæ”¯æŒå¤šè¿›ç¨‹ï¼‰"""
        scaler = MinMaxScaler(feature_range=(-1, 1))
        scaler.fit(feature_data)
        return scaler

    def _split_segments_into_chunks(self, segments: list, chunk_size: int) -> list:
        """å°†æ•°æ®æ®µåˆ—è¡¨åˆ†å‰²æˆå—"""
        chunks = []
        for i in range(0, len(segments), chunk_size):
            end_idx = min(i + chunk_size, len(segments))
            chunks.append(segments[i:end_idx])
        return chunks

    def _apply_normalization_to_chunk(self, segment_chunk: list, feature_columns: list) -> list:
        """å¯¹ä¸€æ‰¹æ•°æ®æ®µåº”ç”¨å½’ä¸€åŒ–"""
        normalized_chunk = []
        for seg in segment_chunk:
            normalized_seg = seg.copy()
            for i, col in enumerate(feature_columns):
                normalized_seg[:, i] = (
                    self.scalers[col]
                    .transform(normalized_seg[:, i].reshape(-1, 1))
                    .flatten()
                )
            normalized_chunk.append(normalized_seg)
        return normalized_chunk

    def _gaf_to_float32(self, data: np.ndarray) -> np.ndarray:
        """Float32è½¬æ¢æ–¹æ³•"""
        batch_size = 1000
        if data.shape[0] <= batch_size:
            return self._process_batch_float32(data)
        else:
            print(f"ä½¿ç”¨åˆ†æ‰¹å¤„ç†ï¼Œæ‰¹å¤§å°: {batch_size}")
            results = []
            for i in range(0, data.shape[0], batch_size):
                end_idx = min(i + batch_size, data.shape[0])
                batch = data[i:end_idx]
                if i % (batch_size * 5) == 0:
                    print(f"å¤„ç†è¿›åº¦: {i}/{data.shape[0]} ({100*i/data.shape[0]:.1f}%)")
                batch_result = self._process_batch_float32(batch)
                results.append(batch_result)
            return np.concatenate(results, axis=0)

    def _process_batch_float32(self, batch_data: np.ndarray) -> np.ndarray:
        """Float32æ‰¹å¤„ç†"""
        data_min, data_max = batch_data.min(), batch_data.max()
        if data_min >= -1.0 and data_max <= 1.0:
            if batch_data.dtype != np.float32:
                result = batch_data.astype(np.float32)
            else:
                result = batch_data.copy()
            result += 1.0
            result *= 127.5
        else:
            result = np.clip(batch_data, -1, 1, dtype=np.float32)
            result += 1.0
            result *= 127.5
        return result

    def _gaf_to_int(self, data: np.ndarray, dtype=np.uint8) -> np.ndarray:
        """æ•´æ•°è½¬æ¢æ–¹æ³•"""
        if dtype == np.uint8:
            max_val = 255
        elif dtype == np.uint16:
            max_val = 65535
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {dtype}")
        
        batch_size = 1000
        if data.shape[0] <= batch_size:
            return self._process_batch_int(data, dtype, max_val)
        else:
            print(f"ä½¿ç”¨åˆ†æ‰¹å¤„ç†ï¼Œæ‰¹å¤§å°: {batch_size}")
            results = []
            for i in range(0, data.shape[0], batch_size):
                end_idx = min(i + batch_size, data.shape[0])
                batch = data[i:end_idx]
                if i % batch_size == 0:
                    print(f"å¤„ç†è¿›åº¦: {i}/{data.shape[0]} ({100*i/data.shape[0]:.1f}%)")
                batch_result = self._process_batch_int(batch, dtype, max_val)
                results.append(batch_result)
            return np.concatenate(results, axis=0)

    def _process_batch_int(self, batch_data: np.ndarray, dtype, max_val: int) -> np.ndarray:
        """æ•´æ•°æ‰¹å¤„ç†"""
        data_min, data_max = batch_data.min(), batch_data.max()
        if data_min >= -1.0 and data_max <= 1.0:
            normalized = (batch_data.astype(np.float64) + 1.0) * (max_val / 2.0)
        else:
            clipped = np.clip(batch_data, -1, 1)
            normalized = (clipped.astype(np.float64) + 1.0) * (max_val / 2.0)
        result = np.round(normalized).astype(dtype)
        return result

    def load_persisted_data(self, path):
        """ä»æ–‡ä»¶åŠ è½½é¢„å¤„ç†å¥½çš„åŒGAFæ•°æ®"""
        with open(path, "rb") as f:
            data = pickle.load(f)

        # æ ¡éªŒåŒGAFæ•°æ®æ ¼å¼å®Œæ•´æ€§
        required_keys = [
            "train_summation", "train_difference", "val_summation", "val_difference",
            "train_labels", "val_labels", "scalers"
        ]
        if not all(key in data for key in required_keys):
            raise ValueError("æŒä¹…åŒ–æ–‡ä»¶æ•°æ®æ ¼å¼ä¸å®Œæ•´ï¼Œå¯èƒ½ç‰ˆæœ¬ä¸å…¼å®¹")
        
        self.train_summation = data["train_summation"]
        self.train_difference = data["train_difference"]
        self.val_summation = data["val_summation"]
        self.val_difference = data["val_difference"]
        self.train_labels = data["train_labels"]
        self.val_labels = data["val_labels"]
        self.scalers = data["scalers"]
        
        # åŠ è½½åŸå§‹æ—¶åºæ•°æ®ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬æ–‡ä»¶ï¼‰
        if "train_time_series" in data and "val_time_series" in data:
            self.train_time_series = data["train_time_series"]
            self.val_time_series = data["val_time_series"]
        else:
            # å¦‚æœæ—§ç‰ˆæœ¬æ–‡ä»¶æ²¡æœ‰æ—¶åºæ•°æ®ï¼Œä»labeled_windowsé‡æ–°ç”Ÿæˆ
            print("è­¦å‘Šï¼šæŒä¹…åŒ–æ–‡ä»¶ä¸­æ²¡æœ‰æ—¶åºæ•°æ®ï¼Œæ­£åœ¨ä»åŸå§‹çª—å£æ•°æ®é‡æ–°ç”Ÿæˆ...")
            if "labeled_windows" in data:
                labeled_windows = data["labeled_windows"]
                train_split = int(len(labeled_windows) * (1 - self.test_size))
                self.train_time_series = labeled_windows[:train_split]
                self.val_time_series = labeled_windows[train_split:]
            else:
                raise ValueError("æŒä¹…åŒ–æ–‡ä»¶ä¸­æ—¢æ²¡æœ‰æ—¶åºæ•°æ®ä¹Ÿæ²¡æœ‰åŸå§‹çª—å£æ•°æ®ï¼Œæ— æ³•ç”Ÿæˆ")
        
        # åŠ è½½æ ‡ç­¾æ˜ å°„
        if "label_to_idx" in data and "idx_to_label" in data:
            self.label_to_idx = data["label_to_idx"]
            self.idx_to_label = data["idx_to_label"]
        else:
            print("è­¦å‘Šï¼šæŒä¹…åŒ–æ–‡ä»¶ä¸­æ²¡æœ‰æ ‡ç­¾æ˜ å°„ï¼Œæ­£åœ¨é‡æ–°ç”Ÿæˆ...")
            unique_labels = sorted(set(self.file_label_map.values()))
            self.label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}
            self.idx_to_label = {idx: label for label, idx in self.label_to_idx.items()}
        
        # åŠ è½½æ•°æ®ç±»å‹æ–¹æ³•
        if "data_type_method" in data:
            saved_method = data["data_type_method"]
            if saved_method != self.data_type_method:
                print(f"è­¦å‘Šï¼šæŒä¹…åŒ–æ–‡ä»¶çš„æ•°æ®ç±»å‹æ–¹æ³•({saved_method})ä¸å½“å‰è®¾ç½®({self.data_type_method})ä¸åŒ¹é…")
                self.data_type_method = saved_method
        
        print(f"âœ… ä» {path} åŠ è½½åŒGAFæ•°æ®å®Œæˆï¼ˆå•è¿›ç¨‹åŠ è½½ï¼Œæ— å­è¿›ç¨‹åˆ›å»ºï¼‰")

    def persist_data(self, path, labeled_windows, labeled_labels):
        """æŒä¹…åŒ–ä¿å­˜é¢„å¤„ç†å¥½çš„åŒGAFæ•°æ®"""
        data = {
            "train_summation": self.train_summation,
            "train_difference": self.train_difference,
            "train_time_series": self.train_time_series,  # æ–°å¢ï¼šä¿å­˜åŸå§‹æ—¶åºæ•°æ®
            "val_summation": self.val_summation,
            "val_difference": self.val_difference,
            "val_time_series": self.val_time_series,      # æ–°å¢ï¼šä¿å­˜åŸå§‹æ—¶åºæ•°æ®
            "train_labels": self.train_labels,
            "val_labels": self.val_labels,
            "scalers": self.scalers,
            "win_size": self.win_size,
            "step": self.step,
            "file_map": self.file_label_map,
            "data_type_method": self.data_type_method,
            "labeled_windows": labeled_windows,
            "labeled_labels": labeled_labels,
            "label_to_idx": self.label_to_idx,
            "idx_to_label": self.idx_to_label,
        }

        with open(path, "wb") as f:
            pickle.dump(data, f)

        print(f"åŒGAFæ•°æ®æŒä¹…åŒ–ä¿å­˜åˆ° {path} å®Œæˆ")


class DualGAFDataLoader(Dataset):
    """
    åŒGAFæ•°æ®é›†è§†å›¾
    è½»é‡çº§çš„DatasetåŒ…è£…å™¨ï¼Œä¸é‡å¤å¤„ç†æ•°æ®ï¼Œæ”¯æŒæ•°æ®å¢å¼º
    """
    
    def __init__(self, args, flag):
        """
        Args:
            args: å‘½ä»¤è¡Œå‚æ•°
            flag: æ•°æ®é›†ç±»å‹ï¼Œ'train' æˆ– 'val'
        """
        self.flag = flag
        self.data_manager = DualGAFDataManager(args)
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ç»Ÿè®¡ç‰¹å¾
        self.use_statistical_features = getattr(args, 'use_statistical_features', True)
        
        # æ ¹æ®flagé€‰æ‹©å¯¹åº”çš„æ•°æ®
        if flag == "train":
            self.summation_data = self.data_manager.train_summation
            self.difference_data = self.data_manager.train_difference
            self.time_series_data = self.data_manager.train_time_series if self.use_statistical_features else None
            self.labels = self.data_manager.train_labels
        elif flag == "val":
            self.summation_data = self.data_manager.val_summation
            self.difference_data = self.data_manager.val_difference
            self.time_series_data = self.data_manager.val_time_series if self.use_statistical_features else None
            self.labels = self.data_manager.val_labels
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„flagå€¼: {flag}ï¼Œåº”ä¸º'train'æˆ–'val'")
        
        print(f"åˆ›å»º{flag}æ•°æ®é›†è§†å›¾ï¼ŒåŒ…å«{len(self)}ä¸ªæ ·æœ¬")
        if self.use_statistical_features:
            print(f"  - å¯ç”¨ç»Ÿè®¡ç‰¹å¾ï¼Œè¿”å›å››å…ƒç»„ (summation, difference, time_series, label)")
        else:
            print(f"  - ç¦ç”¨ç»Ÿè®¡ç‰¹å¾ï¼Œè¿”å›ä¸‰å…ƒç»„ (summation, difference, label)")



    def __len__(self):
        return len(self.labels)

    def __getitem__(self, index):
        """
        æ ¹æ®use_statistical_featureså‚æ•°è¿”å›ä¸åŒçš„æ•°æ®æ ¼å¼ï¼š
        - å¦‚æœå¯ç”¨ç»Ÿè®¡ç‰¹å¾ï¼šè¿”å›å››å…ƒç»„ (summation_data, difference_data, time_series_data, label)
        - å¦‚æœç¦ç”¨ç»Ÿè®¡ç‰¹å¾ï¼šè¿”å›ä¸‰å…ƒç»„ (summation_data, difference_data, label)
        """
        summation_data = self.summation_data[index]
        difference_data = self.difference_data[index]
        label = self.labels[index]
        
        # å¦‚æœä½¿ç”¨æ•´æ•°ç±»å‹å­˜å‚¨ï¼Œéœ€è¦è½¬æ¢å›æµ®ç‚¹æ•°è¿›è¡Œè®­ç»ƒ
        if self.data_manager.data_type_method in ['uint8', 'uint16']:
            summation_data = summation_data.astype(np.float32)
            difference_data = difference_data.astype(np.float32)
        
        # è½¬æ¢ä¸ºtorchå¼ é‡
        summation_data = torch.from_numpy(summation_data.astype(np.float32))
        difference_data = torch.from_numpy(difference_data.astype(np.float32))
        # ç¡®ä¿æ ‡ç­¾æ˜¯æ ‡é‡ä½†åœ¨æŸå¤±è®¡ç®—æ—¶èƒ½æ­£ç¡®å¤„ç†
        label_tensor = torch.tensor(label, dtype=torch.long)
        
        if self.use_statistical_features:
            # è¿”å›å››å…ƒç»„
            time_series_data = self.time_series_data[index]
            time_series_data = torch.from_numpy(time_series_data.astype(np.float32))
            return summation_data, difference_data, time_series_data, label_tensor
        else:
            # è¿”å›ä¸‰å…ƒç»„
            return summation_data, difference_data, label_tensor
    
    @property
    def label_to_idx(self):
        """è·å–æ ‡ç­¾æ˜ å°„"""
        return self.data_manager.label_to_idx
    
    @property
    def idx_to_label(self):
        """è·å–ç´¢å¼•åˆ°æ ‡ç­¾çš„æ˜ å°„"""
        return self.data_manager.idx_to_label

"""
å¹¶è¡Œä¼˜åŒ–çš„åŒGAFæ•°æ®åŠ è½½å™¨ä½¿ç”¨ç¤ºä¾‹ï¼š

# 1. åŸºç¡€é…ç½® - å¯ç”¨å¹¶è¡Œå¤„ç†
class Args:
    def __init__(self):
        self.root_path = './dataset/SAHU'
        self.seq_len = 72
        self.step = 12
        self.test_size = 0.3
        self.data_type_method = 'uint8'  # æˆ– 'float32', 'uint16'
        self.batch_size = 32
        self.num_workers = 4
        self.use_statistical_features = True
        
        # å¹¶è¡Œå¤„ç†ä¼˜åŒ–é…ç½®
        self.n_jobs = 8                    # å¹¶è¡Œè¿›ç¨‹æ•°ï¼Œå»ºè®®è®¾ä¸ºCPUæ ¸å¿ƒæ•°
        self.use_multiprocessing = True    # å¯ç”¨å¤šè¿›ç¨‹å¤„ç†
        self.chunk_size = 100              # æ¯ä¸ªè¿›ç¨‹å¤„ç†çš„æ•°æ®å—å¤§å°

# 2. é«˜çº§é…ç½® - é’ˆå¯¹ä¸åŒç¡¬ä»¶ç¯å¢ƒçš„ä¼˜åŒ–
class OptimizedArgs:
    def __init__(self):
        # åŸºç¡€é…ç½®
        self.root_path = './dataset/SAHU'
        self.seq_len = 96
        self.step = 24
        self.test_size = 0.2
        self.data_type_method = 'uint8'
        self.use_statistical_features = True
        
        # æ ¹æ®ç³»ç»Ÿèµ„æºåŠ¨æ€é…ç½®å¹¶è¡Œå‚æ•°
        import multiprocessing as mp
        cpu_count = mp.cpu_count()
        
        # å¤§å†…å­˜ç³»ç»Ÿé…ç½® (32GB+)
        if cpu_count >= 16:
            self.n_jobs = min(cpu_count - 2, 12)  # ä¿ç•™2ä¸ªæ ¸å¿ƒç»™ç³»ç»Ÿ
            self.chunk_size = 200                 # è¾ƒå¤§çš„å—å¤§å°
            self.use_multiprocessing = True
        # ä¸­ç­‰ç³»ç»Ÿé…ç½® (16GB)
        elif cpu_count >= 8:
            self.n_jobs = min(cpu_count - 1, 8)
            self.chunk_size = 100
            self.use_multiprocessing = True
        # å°ç³»ç»Ÿé…ç½® (8GB)
        else:
            self.n_jobs = max(cpu_count // 2, 2)
            self.chunk_size = 50
            self.use_multiprocessing = True

# 3. ä½¿ç”¨ç¤ºä¾‹
def example_usage():
    # åˆ›å»ºä¼˜åŒ–é…ç½®
    args = OptimizedArgs()
    
    print("=== å¹¶è¡Œä¼˜åŒ–çš„åŒGAFæ•°æ®å¤„ç† ===")
    print(f"ç³»ç»Ÿé…ç½® - CPUæ ¸å¿ƒæ•°: {args.n_jobs}, å—å¤§å°: {args.chunk_size}")
    print(f"æ•°æ®ç±»å‹: {args.data_type_method}, å¤šè¿›ç¨‹: {args.use_multiprocessing}")
    
    # åˆ›å»ºæ•°æ®é›†ï¼ˆè‡ªåŠ¨è¿›è¡Œå¹¶è¡Œå¤„ç†ï¼‰
    from data_provider.data_factory import data_provider
    
    # ç¬¬ä¸€æ¬¡è¿è¡Œä¼šè¿›è¡Œå¹¶è¡Œæ•°æ®å¤„ç†
    start_time = time.time()
    train_dataset, train_loader = data_provider(args, flag='train')
    val_dataset, val_loader = data_provider(args, flag='val')
    processing_time = time.time() - start_time
    
    print(f"\n=== å¤„ç†å®Œæˆ ===")
    print(f"æ€»å¤„ç†æ—¶é—´: {processing_time:.2f}s")
    print(f"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
    print(f"éªŒè¯é›†å¤§å°: {len(val_dataset)}")
    
    # å†…å­˜ä½¿ç”¨ç»Ÿè®¡
    train_summation_memory = train_dataset.summation_data.nbytes / 1024**3
    train_difference_memory = train_dataset.difference_data.nbytes / 1024**3
    print(f"å†…å­˜å ç”¨ - Summation GAF: {train_summation_memory:.2f}GB")
    print(f"å†…å­˜å ç”¨ - Difference GAF: {train_difference_memory:.2f}GB")
    
    return train_dataset, val_dataset

# 4. æ€§èƒ½è°ƒä¼˜å»ºè®®

æ€§èƒ½ä¼˜åŒ–tips:

1. **è¿›ç¨‹æ•°é…ç½®**:
   - CPUå¯†é›†å‹ä»»åŠ¡ï¼šn_jobs = CPUæ ¸å¿ƒæ•° - 1
   - å†…å­˜å¯†é›†å‹ä»»åŠ¡ï¼šn_jobs = min(CPUæ ¸å¿ƒæ•°, å¯ç”¨å†…å­˜GB // 2)
   - é¿å…è®¾ç½®è¿‡é«˜å¯¼è‡´ä¸Šä¸‹æ–‡åˆ‡æ¢å¼€é”€

2. **å—å¤§å°è°ƒä¼˜**:
   - å¤§å†…å­˜ç³»ç»Ÿ: chunk_size = 200-500
   - ä¸­ç­‰å†…å­˜ç³»ç»Ÿ: chunk_size = 100-200  
   - å°å†…å­˜ç³»ç»Ÿ: chunk_size = 50-100
   - è¿‡å°çš„å—ä¼šå¢åŠ è¿›ç¨‹é—´é€šä¿¡å¼€é”€

3. **æ•°æ®ç±»å‹é€‰æ‹©**:
   - uint8: æœ€èŠ‚çœå†…å­˜ï¼Œé€‚åˆå¤§æ•°æ®é›†
   - uint16: å¹³è¡¡å†…å­˜å’Œç²¾åº¦
   - float32: æœ€é«˜ç²¾åº¦ï¼Œå†…å­˜å ç”¨æœ€å¤§

4. **å¹¶è¡Œç­–ç•¥**:
   - GAFè½¬æ¢: ä½¿ç”¨å¤šè¿›ç¨‹ (CPUå¯†é›†å‹)
   - æ•°æ®ç±»å‹è½¬æ¢: ä½¿ç”¨å¤šçº¿ç¨‹ (I/Oå¯†é›†å‹)
   - ç‰¹å¾å½’ä¸€åŒ–: ä½¿ç”¨å¤šçº¿ç¨‹ (å†…å­˜è®¿é—®å¯†é›†å‹)

5. **å†…å­˜ä¼˜åŒ–**:
   - å¯ç”¨æ•°æ®æŒä¹…åŒ–é¿å…é‡å¤å¤„ç†
   - ä½¿ç”¨uint8æ•°æ®ç±»å‹å‡å°‘å†…å­˜å ç”¨75%
   - åŠæ—¶é‡Šæ”¾ä¸­é—´å˜é‡

6. **ç¦ç”¨å¹¶è¡Œå¤„ç†çš„æƒ…å†µ**:
   - æ•°æ®é‡å¾ˆå° (< chunk_size * 2)
   - å†…å­˜ä¸è¶³çš„ç³»ç»Ÿ
   - è°ƒè¯•æ¨¡å¼
   - è®¾ç½® use_multiprocessing = False

ä½¿ç”¨æ—¶é—´å¯¹æ¯” (åŸºäº8æ ¸CPU, 16GBå†…å­˜):
- åŸå§‹å•è¿›ç¨‹: ~300s
- å¹¶è¡Œä¼˜åŒ–å: ~60s  
- æ€§èƒ½æå‡: ~5x

æ³¨æ„äº‹é¡¹:
- é¦–æ¬¡è¿è¡Œä¼šè¿›è¡Œæ•°æ®å¤„ç†ï¼Œåç»­è¿è¡Œç›´æ¥åŠ è½½ç¼“å­˜
- ç¡®ä¿æœ‰è¶³å¤Ÿå†…å­˜åŒæ—¶å¤„ç†å¤šä¸ªæ•°æ®å—
- åœ¨Windowsä¸Šå¯èƒ½éœ€è¦é¢å¤–é…ç½®å¤šè¿›ç¨‹æ”¯æŒ
"""
