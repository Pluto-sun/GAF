# 块大小优化测试指南

## 📖 概述

这套测试脚本用于优化GAF计算和数据类型转换的块大小配置，通过测试不同的块大小和处理模式（标准多进程 vs 共享内存），找出最适合当前服务器的最优配置。

## 🚀 快速开始

### 1. 快速验证测试
```bash
# 运行快速测试（1000样本，用于验证功能）
python test_chunk_size_quick.py
```

### 2. 完整性能测试  
```bash
# 运行完整测试（5000样本，获得准确的性能数据）
python test_chunk_size_optimization.py
```

## 📊 测试内容

### 🧮 GAF计算优化
- **测试项目**: Summation GAF 和 Difference GAF 矩阵生成
- **处理模式**: 
  - 标准多进程 (ProcessPoolExecutor)
  - 共享内存多进程 (Shared Memory + ProcessPoolExecutor)
- **测试参数**: 不同的块大小 (50, 100, 200, 300, 500, 800, 1000, 1500, 2000)
- **测试进程数**: 2, 4, 6, 8, 12个进程

### 🔄 数据类型转换优化
- **测试项目**: float32 → uint8/uint16 数据类型转换
- **处理模式**:
  - 标准多线程 (ThreadPoolExecutor)  
  - 共享内存多线程 (Shared Memory + ThreadPoolExecutor)
- **测试参数**: 相同的块大小范围
- **测试线程数**: 4, 8, 12个线程

### 📏 基准测试
- **单线程GAF生成**: 建立性能基准
- **单线程数据转换**: 建立转换基准
- **内存使用监控**: 实时监控内存变化
- **CPU使用率统计**: 记录CPU负载

## 📈 输出结果

### 控制台输出
```
🔬 块大小优化测试脚本
============================================================
🖥️  CPU核心数: 16
💾 总内存: 64.0GB
🔢 测试样本数: 5000

📊 测试数据生成完成: (5000, 96, 12)
💻 数据大小: 0.22GB

=== 单线程基准测试 ===
...
📈 单线程基准结果:
   gaf_summation_time: 45.23s
   conversion_uint8_time: 12.34s

=== GAF计算块大小优化测试 ===
...
   📊 标准多进程: 8.45s (加速: 5.35x)
   🚀 共享内存: 7.21s (加速: 6.27x)
   ✅ 结果一致性: True

=== 结果分析与推荐 ===
🎯 系统推荐配置 (基于当前硬件: 16核, 64.0GB):
   🧮 GAF计算推荐:
      8进程 - 标准: 500 (5.35x), 共享内存: 800 (6.27x)
   🔄 数据转换推荐:
      8线程 - 标准: 200 (4.12x), 共享内存: 300 (4.58x)
```

### 保存的文件
```
test_results/
├── gaf_chunk_size_results.csv      # GAF测试详细结果
├── conversion_chunk_size_results.csv  # 转换测试详细结果
└── baseline_results.csv              # 基准测试结果
```

## 🎯 结果解读

### 最优配置推荐

基于测试结果，脚本会自动推荐：

1. **GAF计算最优配置**:
   - 进程数: 通常为CPU核心数-2到CPU核心数
   - 块大小: 根据内存大小，通常在200-800之间
   - 处理模式: 共享内存通常比标准多进程快10-20%

2. **数据转换最优配置**:
   - 线程数: CPU核心数的50%-100%
   - 块大小: 通常比GAF计算的块大小小，在100-500之间
   - 处理模式: 共享内存适合大数据，标准多线程适合中小数据

### 性能指标解读

- **加速比 (Speedup)**: 相对于单线程的性能提升倍数
  - 2-3x: 一般性能提升
  - 4-6x: 良好性能提升  
  - 6x+: 优秀性能提升

- **结果一致性**: 验证并行处理结果的正确性
  - True: 并行结果与单线程结果一致
  - False: 存在计算误差，需要检查配置

## ⚙️ 自定义配置

### 修改测试参数
```python
# 在脚本中修改这些参数
test_samples = 5000  # 测试样本数
chunk_sizes = [50, 100, 200, 500, 1000]  # 测试的块大小
n_jobs_list = [4, 8, 12]  # 测试的进程/线程数
```

### 针对特定硬件优化
```python
# 大内存服务器 (32GB+)
chunk_sizes = [200, 500, 800, 1000, 1500]
n_jobs_list = [8, 12, 16]

# 中等服务器 (16GB)  
chunk_sizes = [100, 200, 300, 500, 800]
n_jobs_list = [4, 6, 8]

# 小服务器 (8GB)
chunk_sizes = [50, 100, 200, 300]
n_jobs_list = [2, 4, 6]
```

## 🔧 故障排除

### 常见问题

1. **内存不足错误**:
   ```
   解决方案: 减少test_samples或chunk_size
   建议: test_samples=1000, chunk_sizes=[50, 100, 200]
   ```

2. **共享内存测试失败**:
   ```
   原因: Windows系统或旧版Python可能不支持
   解决: 测试会自动回退到标准多进程/多线程
   ```

3. **进程数过多导致性能下降**:
   ```
   原因: 上下文切换开销大于并行收益
   建议: 减少n_jobs到CPU核心数的50-75%
   ```

### 系统要求

- **最低配置**: 4核CPU, 8GB RAM
- **推荐配置**: 8核CPU, 16GB+ RAM  
- **理想配置**: 16核CPU, 32GB+ RAM

- **依赖库**: 
  ```bash
  pip install numpy pandas psutil pyts scikit-learn
  ```

## 📊 应用建议

### 将测试结果应用到实际项目

1. **更新DualGAFDataLoader配置**:
```python
# 基于测试结果更新配置
args.n_jobs = 8              # 根据测试推荐的进程数
args.chunk_size = 500        # 根据测试推荐的块大小
args.use_multiprocessing = True
args.use_shared_memory = True  # 如果共享内存表现更好
```

2. **根据数据规模调整**:
```python
# 大数据集 (>10000样本)
recommended_chunk_size = max(test_result_chunk_size, 500)

# 中等数据集 (1000-10000样本)  
recommended_chunk_size = test_result_chunk_size

# 小数据集 (<1000样本)
recommended_chunk_size = min(test_result_chunk_size, 200)
```

## 🎓 性能调优技巧

1. **内存优化**: 
   - 使用uint8数据类型减少75%内存占用
   - 启用数据持久化避免重复处理

2. **CPU优化**:
   - GAF计算使用多进程（CPU密集型）
   - 数据转换使用多线程（内存访问密集型）

3. **I/O优化**:
   - 合理设置块大小平衡并行度和通信开销
   - 避免块大小过小导致频繁进程间通信

## 📞 支持

如果遇到问题或需要进一步优化建议，可以：

1. 查看保存的CSV结果文件进行详细分析
2. 根据系统监控调整测试参数
3. 考虑硬件升级以获得更好的性能

---

**注意**: 测试结果可能因系统负载、硬件配置等因素而变化，建议在相对空闲的系统环境下进行测试以获得准确结果。 