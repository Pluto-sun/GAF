#!/usr/bin/env python3
"""
å¹¶è¡Œä¼˜åŒ–æ€§èƒ½æµ‹è¯•è„šæœ¬

æµ‹è¯•DualGAFDataLoaderçš„å¹¶è¡Œå¤„ç†æ€§èƒ½æ”¹è¿›
æ¯”è¾ƒå•è¿›ç¨‹vså¤šè¿›ç¨‹çš„å¤„ç†æ—¶é—´å’Œèµ„æºä½¿ç”¨æƒ…å†µ
"""

import os
import sys
import time
import multiprocessing as mp
import numpy as np
import psutil
from contextlib import contextmanager

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from data_provider.data_loader.DualGAFDataLoader import DualGAFDataManager


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§ç±»"""
    def __init__(self):
        self.stats = {}
        
    def __enter__(self):
        self.process = psutil.Process()
        self.start_time = time.time()
        self.start_memory = self.process.memory_info().rss / 1024**3  # GB
        self.start_cpu_percent = self.process.cpu_percent()
        
        print(f"å¼€å§‹ç›‘æ§ - å†…å­˜: {self.start_memory:.2f}GB")
        return self
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        end_time = time.time()
        end_memory = self.process.memory_info().rss / 1024**3  # GB
        end_cpu_percent = self.process.cpu_percent()
        
        elapsed_time = end_time - self.start_time
        memory_diff = end_memory - self.start_memory
        
        print(f"æ€§èƒ½ç»Ÿè®¡:")
        print(f"  æ‰§è¡Œæ—¶é—´: {elapsed_time:.2f}ç§’")
        print(f"  å†…å­˜å˜åŒ–: {memory_diff:+.2f}GB")
        print(f"  å³°å€¼å†…å­˜: {end_memory:.2f}GB")
        print(f"  CPUä½¿ç”¨ç‡: {end_cpu_percent:.1f}%")
        
        self.stats = {
            'time': elapsed_time,
            'memory_diff': memory_diff,
            'peak_memory': end_memory,
            'cpu_percent': end_cpu_percent
        }


def monitor_performance():
    """è¿”å›æ€§èƒ½ç›‘æ§å™¨å®ä¾‹"""
    return PerformanceMonitor()


class TestArgs:
    """æµ‹è¯•ç”¨å‚æ•°é…ç½®"""
    def __init__(self, use_parallel=True, n_jobs=None, chunk_size=100):
        self.root_path = "./dataset/SAHU/direct_5_working"
        self.seq_len = 96
        self.step = 96
        self.test_size = 0.2
        self.data_type_method = 'uint8'
        
        # å¹¶è¡Œé…ç½®
        if n_jobs is None:
            n_jobs = min(mp.cpu_count(), 8)
            
        self.n_jobs = n_jobs if use_parallel else 1
        self.use_multiprocessing = use_parallel
        self.chunk_size = chunk_size
        
        print(f"æµ‹è¯•é…ç½® - å¹¶è¡Œ: {use_parallel}, è¿›ç¨‹æ•°: {self.n_jobs}, å—å¤§å°: {chunk_size}")


def create_synthetic_test_data():
    """åˆ›å»ºåˆæˆæµ‹è¯•æ•°æ®ï¼Œç”¨äºåœ¨æ²¡æœ‰çœŸå®æ•°æ®æ—¶è¿›è¡Œæµ‹è¯•"""
    print("åˆ›å»ºåˆæˆæµ‹è¯•æ•°æ®...")
    
    # æ¨¡æ‹Ÿæ–‡ä»¶æ•°æ®ç»“æ„
    n_samples = 4000
    n_features = 26
    seq_len = 96
    
    # ç”Ÿæˆæ—¶åºæ•°æ®
    data = []
    for i in range(n_samples):
        # ç”Ÿæˆå¸¦æœ‰è¶‹åŠ¿å’Œå™ªå£°çš„æ—¶åºæ•°æ®
        trend = np.linspace(0, 1, seq_len)
        noise = np.random.normal(0, 0.1, (seq_len, n_features))
        seasonal = np.sin(2 * np.pi * np.arange(seq_len) / 24)[:, np.newaxis]
        
        sample = trend[:, np.newaxis] + seasonal + noise
        data.append(sample)
    
    return np.array(data)


def test_gaf_generation_performance():
    """æµ‹è¯•GAFç”Ÿæˆçš„æ€§èƒ½"""
    print("\n" + "="*60)
    print("GAFç”Ÿæˆæ€§èƒ½æµ‹è¯•")
    print("="*60)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = create_synthetic_test_data()
    print(f"æµ‹è¯•æ•°æ®å½¢çŠ¶: {test_data.shape}")
    
    results = {}
    
    # æµ‹è¯•å•è¿›ç¨‹
    print(f"\n--- å•è¿›ç¨‹æµ‹è¯• ---")
    args_single = TestArgs(use_parallel=False)
    manager_single = DualGAFDataManager.__new__(DualGAFDataManager, args_single)
    manager_single.args = args_single
    manager_single.n_jobs = 16
    manager_single.use_multiprocessing = False
    manager_single.chunk_size = 100
    
    with monitor_performance() as monitor:
        result_single = manager_single._generate_gaf_matrix_single(test_data, "summation", False)
    
    results['single_process'] = monitor.stats
    print(f"ç»“æœå½¢çŠ¶: {result_single.shape}")
    
    # æµ‹è¯•å¤šè¿›ç¨‹
    print(f"\n--- å¤šè¿›ç¨‹æµ‹è¯• ---")
    args_multi = TestArgs(use_parallel=True, n_jobs=16, chunk_size=100)
    manager_multi = DualGAFDataManager.__new__(DualGAFDataManager, args_multi)
    manager_multi.args = args_multi
    manager_multi.n_jobs = 16
    manager_multi.use_multiprocessing = True
    manager_multi.chunk_size = 100
    
    with monitor_performance() as monitor:
        result_multi = manager_multi.generate_gaf_matrix_parallel(test_data, "summation", False)
    
    results['multi_process'] = monitor.stats
    print(f"ç»“æœå½¢çŠ¶: {result_multi.shape}")
    
    # éªŒè¯ç»“æœä¸€è‡´æ€§
    print(f"\n--- ç»“æœéªŒè¯ ---")
    if np.allclose(result_single, result_multi, rtol=1e-5):
        print("âœ“ å•è¿›ç¨‹å’Œå¤šè¿›ç¨‹ç»“æœä¸€è‡´")
    else:
        print("âœ— ç»“æœä¸ä¸€è‡´ï¼Œéœ€è¦æ£€æŸ¥å®ç°")
        diff = np.abs(result_single - result_multi).mean()
        print(f"å¹³å‡å·®å¼‚: {diff}")
    
    return results


def test_data_conversion_performance():
    """æµ‹è¯•æ•°æ®ç±»å‹è½¬æ¢çš„æ€§èƒ½"""
    print("\n" + "="*60)
    print("æ•°æ®ç±»å‹è½¬æ¢æ€§èƒ½æµ‹è¯•")
    print("="*60)
    
    # åˆ›å»ºGAFæ•°æ® (æ¨¡æ‹Ÿ)
    n_samples, n_channels, height, width = 2000, 26, 72, 72
    test_gaf_data = np.random.uniform(-1, 1, (n_samples, n_channels, height, width)).astype(np.float32)
    print(f"æµ‹è¯•GAFæ•°æ®å½¢çŠ¶: {test_gaf_data.shape}")
    print(f"æ•°æ®å¤§å°: {test_gaf_data.nbytes / 1024**3:.2f}GB")
    
    results = {}
    
    # æµ‹è¯•å•è¿›ç¨‹
    print(f"\n--- å•è¿›ç¨‹è½¬æ¢æµ‹è¯• ---")
    args_single = TestArgs(use_parallel=False)
    manager_single = DualGAFDataManager.__new__(DualGAFDataManager, args_single)
    manager_single.args = args_single
    manager_single.data_type_method = 'uint8'
    manager_single.n_jobs = 1
    manager_single.use_multiprocessing = False
    manager_single.chunk_size = 100
    
    with monitor_performance() as monitor:
        result_single = manager_single._gaf_to_int(test_gaf_data, dtype=np.uint8)
    
    results['single_conversion'] = monitor.stats
    print(f"è½¬æ¢åæ•°æ®ç±»å‹: {result_single.dtype}")
    print(f"è½¬æ¢åå¤§å°: {result_single.nbytes / 1024**3:.2f}GB")
    
    # æµ‹è¯•å¤šè¿›ç¨‹
    print(f"\n--- å¤šè¿›ç¨‹è½¬æ¢æµ‹è¯• ---")
    args_multi = TestArgs(use_parallel=True, n_jobs=16, chunk_size=50)
    manager_multi = DualGAFDataManager.__new__(DualGAFDataManager, args_multi)
    manager_multi.args = args_multi
    manager_multi.data_type_method = 'uint8'
    manager_multi.n_jobs = 16
    manager_multi.use_multiprocessing = True
    manager_multi.chunk_size = 100
    
    with monitor_performance() as monitor:
        result_multi = manager_multi._gaf_to_int_parallel(test_gaf_data, dtype=np.uint8)
    
    results['multi_conversion'] = monitor.stats
    print(f"è½¬æ¢åæ•°æ®ç±»å‹: {result_multi.dtype}")
    print(f"è½¬æ¢åå¤§å°: {result_multi.nbytes / 1024**3:.2f}GB")
    
    # éªŒè¯ç»“æœä¸€è‡´æ€§
    print(f"\n--- ç»“æœéªŒè¯ ---")
    if np.array_equal(result_single, result_multi):
        print("âœ“ å•è¿›ç¨‹å’Œå¤šè¿›ç¨‹è½¬æ¢ç»“æœä¸€è‡´")
    else:
        print("âœ— è½¬æ¢ç»“æœä¸ä¸€è‡´")
        diff_count = np.sum(result_single != result_multi)
        print(f"ä¸åŒå…ƒç´ æ•°é‡: {diff_count} / {result_single.size}")
    
    return results


def print_performance_summary(gaf_results, conversion_results):
    """æ‰“å°æ€§èƒ½æ€»ç»“"""
    print("\n" + "="*60)
    print("æ€§èƒ½æµ‹è¯•æ€»ç»“")
    print("="*60)
    
    print("\nğŸ“Š GAFç”Ÿæˆæ€§èƒ½å¯¹æ¯”:")
    single_time = gaf_results['single_process']['time']
    multi_time = gaf_results['multi_process']['time']
    speedup = single_time / multi_time if multi_time > 0 else 0
    
    print(f"  å•è¿›ç¨‹æ—¶é—´: {single_time:.2f}s")
    print(f"  å¤šè¿›ç¨‹æ—¶é—´: {multi_time:.2f}s")
    print(f"  åŠ é€Ÿæ¯”: {speedup:.2f}x")
    
    if speedup > 1.5:
        print("  âœ“ æ˜¾è‘—æ€§èƒ½æå‡")
    elif speedup > 1.1:
        print("  âœ“ é€‚åº¦æ€§èƒ½æå‡")
    else:
        print("  âš ï¸  æ€§èƒ½æå‡æœ‰é™")
    
    print("\nğŸ“Š æ•°æ®è½¬æ¢æ€§èƒ½å¯¹æ¯”:")
    single_conv_time = conversion_results['single_conversion']['time']
    multi_conv_time = conversion_results['multi_conversion']['time']
    conv_speedup = single_conv_time / multi_conv_time if multi_conv_time > 0 else 0
    
    print(f"  å•è¿›ç¨‹æ—¶é—´: {single_conv_time:.2f}s")
    print(f"  å¤šè¿›ç¨‹æ—¶é—´: {multi_conv_time:.2f}s")
    print(f"  åŠ é€Ÿæ¯”: {conv_speedup:.2f}x")
    
    if conv_speedup > 1.5:
        print("  âœ“ æ˜¾è‘—æ€§èƒ½æå‡")
    elif conv_speedup > 1.1:
        print("  âœ“ é€‚åº¦æ€§èƒ½æå‡")
    else:
        print("  âš ï¸  æ€§èƒ½æå‡æœ‰é™")
    
    # ç³»ç»Ÿä¿¡æ¯
    print(f"\nğŸ–¥ï¸  ç³»ç»Ÿä¿¡æ¯:")
    print(f"  CPUæ ¸å¿ƒæ•°: {mp.cpu_count()}")
    print(f"  å¯ç”¨å†…å­˜: {psutil.virtual_memory().available / 1024**3:.2f}GB")
    print(f"  æ€»å†…å­˜: {psutil.virtual_memory().total / 1024**3:.2f}GB")
    
    # ä¼˜åŒ–å»ºè®®
    print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
    if speedup < 1.5:
        print("  - è€ƒè™‘å¢åŠ chunk_sizeä»¥å‡å°‘è¿›ç¨‹é€šä¿¡å¼€é”€")
        print("  - æ£€æŸ¥ç³»ç»Ÿèµ„æºæ˜¯å¦å……è¶³")
        print("  - å¯¹äºå°æ•°æ®é›†ï¼Œå•è¿›ç¨‹å¯èƒ½æ›´é«˜æ•ˆ")
    
    if conv_speedup < 1.2:
        print("  - æ•°æ®è½¬æ¢å¯èƒ½å—I/Oé™åˆ¶ï¼Œè€ƒè™‘ä½¿ç”¨SSD")
        print("  - é€‚å½“è°ƒæ•´è¿›ç¨‹æ•°å’Œå—å¤§å°")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("DualGAFDataLoader å¹¶è¡Œä¼˜åŒ–æ€§èƒ½æµ‹è¯•")
    print("="*60)
    print(f"Pythonç‰ˆæœ¬: {sys.version}")
    print(f"CPUæ ¸å¿ƒæ•°: {mp.cpu_count()}")
    print(f"å¯ç”¨å†…å­˜: {psutil.virtual_memory().available / 1024**3:.2f}GB")
    
    try:
        # æµ‹è¯•GAFç”Ÿæˆæ€§èƒ½
        gaf_results = test_gaf_generation_performance()
        
        # æµ‹è¯•æ•°æ®è½¬æ¢æ€§èƒ½
        conversion_results = test_data_conversion_performance()
        
        # æ‰“å°æ€»ç»“
        print_performance_summary(gaf_results, conversion_results)
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    print(f"\nâœ… æ€§èƒ½æµ‹è¯•å®Œæˆ")
    return 0


if __name__ == "__main__":
    exit(main()) 