#!/usr/bin/env python3
"""
é«˜ç«¯æœåŠ¡å™¨æ€§èƒ½ä¼˜åŒ–æµ‹è¯•è„šæœ¬
é’ˆå¯¹32æ ¸128GBæœåŠ¡å™¨çš„GAFå¤„ç†ä¼˜åŒ–
"""

import os
import sys
import time
import numpy as np
import psutil
import multiprocessing as mp
from contextlib import contextmanager

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from data_provider.data_loader.DualGAFDataLoader import DualGAFDataManager


@contextmanager
def performance_monitor():
    """æ€§èƒ½ç›‘æ§ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    process = psutil.Process()
    start_time = time.time()
    start_memory = process.memory_info().rss / 1024**3  # GB
    
    # è®°å½•å¼€å§‹æ—¶çš„CPUçŠ¶æ€
    cpu_percent_start = psutil.cpu_percent(interval=None)
    
    yield
    
    end_time = time.time()
    end_memory = process.memory_info().rss / 1024**3  # GB
    
    # è®°å½•ç»“æŸæ—¶çš„CPUçŠ¶æ€
    cpu_percent_end = psutil.cpu_percent(interval=None)
    
    elapsed_time = end_time - start_time
    memory_diff = end_memory - start_memory
    
    print(f"  â±ï¸  æ‰§è¡Œæ—¶é—´: {elapsed_time:.2f}ç§’")
    print(f"  ğŸ’¾ å†…å­˜å˜åŒ–: {memory_diff:+.2f}GB")
    print(f"  ğŸ“Š å³°å€¼å†…å­˜: {end_memory:.2f}GB")
    print(f"  ğŸ–¥ï¸  å¹³å‡CPUä½¿ç”¨ç‡: {cpu_percent_end:.1f}%")


def create_large_test_data(n_samples=8000, n_features=26, seq_len=96):
    """åˆ›å»ºå¤§è§„æ¨¡æµ‹è¯•æ•°æ®"""
    print(f"ğŸ“¦ åˆ›å»ºå¤§è§„æ¨¡æµ‹è¯•æ•°æ®: {n_samples} æ ·æœ¬ Ã— {n_features} ç‰¹å¾ Ã— {seq_len} æ—¶é—´ç‚¹")
    
    # æ¨¡æ‹ŸçœŸå®çš„HVACæ•°æ®æ¨¡å¼
    data = []
    for i in range(n_samples):
        # åŸºç¡€æ—¶åºæ¨¡å¼
        time_points = np.arange(seq_len)
        
        # æ¸©åº¦æ•°æ®æ¨¡æ‹Ÿ (å‰9ä¸ªç‰¹å¾)
        temp_base = 20 + 5 * np.sin(2 * np.pi * time_points / 24)  # æ—¥å‘¨æœŸ
        temp_noise = np.random.normal(0, 0.5, (seq_len, 9))
        temp_data = temp_base[:, np.newaxis] + temp_noise
        
        # æµé‡æ•°æ®æ¨¡æ‹Ÿ (ä¸­é—´ç‰¹å¾)
        flow_pattern = 50 + 20 * np.sin(2 * np.pi * time_points / 12)  # åŠæ—¥å‘¨æœŸ
        flow_noise = np.random.normal(0, 2, (seq_len, 8))
        flow_data = flow_pattern[:, np.newaxis] + flow_noise
        
        # æ§åˆ¶ä¿¡å·æ¨¡æ‹Ÿ (åé¢ç‰¹å¾)
        control_base = np.random.choice([0, 1], size=seq_len, p=[0.3, 0.7])
        control_noise = np.random.normal(0, 0.1, (seq_len, n_features - 17))
        control_data = control_base[:, np.newaxis] + control_noise
        
        # ç»„åˆæ‰€æœ‰ç‰¹å¾
        sample = np.concatenate([temp_data, flow_data, control_data], axis=1)
        
        # æ ‡å‡†åŒ–åˆ°[-1, 1]èŒƒå›´
        sample = 2 * (sample - sample.min()) / (sample.max() - sample.min()) - 1
        
        data.append(sample)
    
    result = np.array(data)
    print(f"  ğŸ“Š æ•°æ®å¤§å°: {result.nbytes / 1024**3:.2f}GB")
    print(f"  ğŸ“ æ•°æ®å½¢çŠ¶: {result.shape}")
    return result


class HighEndServerTestArgs:
    """é«˜ç«¯æœåŠ¡å™¨æµ‹è¯•é…ç½®"""
    def __init__(self, n_jobs=20, chunk_size=800, use_shared_memory=True):
        self.root_path = "./dataset/SAHU/direct_5_working"
        self.seq_len = 96
        self.step = 96
        self.test_size = 0.2
        self.data_type_method = 'uint8'
        
        # é«˜ç«¯æœåŠ¡å™¨ä¼˜åŒ–é…ç½®
        self.n_jobs = n_jobs
        self.use_multiprocessing = True
        self.chunk_size = chunk_size
        self.use_shared_memory = use_shared_memory


def analyze_process_utilization():
    """åˆ†æè¿›ç¨‹åˆ©ç”¨ç‡å’Œèµ„æºæµªè´¹é—®é¢˜"""
    print("\nğŸ“Š è¿›ç¨‹åˆ©ç”¨ç‡åˆ†æ")
    print("=" * 80)
    
    N = 2000  # å›ºå®šæ ·æœ¬æ•°
    test_scenarios = [
        # (chunk_size, n_jobs, description)
        (1000, 12, "å¤§å—å°è¿›ç¨‹æ•° - ç†æƒ³æƒ…å†µ"),
        (1000, 20, "å¤§å—å¤šè¿›ç¨‹æ•° - èµ„æºæµªè´¹"),
        (500, 12, "ä¸­å—é€‚ä¸­è¿›ç¨‹æ•°"),
        (500, 20, "ä¸­å—å¤šè¿›ç¨‹æ•°"),
        (200, 12, "å°å—é€‚ä¸­è¿›ç¨‹æ•°"),
        (200, 20, "å°å—å¤šè¿›ç¨‹æ•°"),
    ]
    
    print(f"ğŸ“¦ æµ‹è¯•æ•°æ®: {N} æ ·æœ¬")
    print()
    
    for chunk_size, n_jobs, description in test_scenarios:
        # è®¡ç®—å®é™…å—æ•°å’Œè¿›ç¨‹åˆ©ç”¨ç‡
        num_chunks = (N + chunk_size - 1) // chunk_size
        effective_processes = min(n_jobs, num_chunks)
        utilization = effective_processes / n_jobs
        wasted_processes = n_jobs - effective_processes
        
        print(f"ğŸ”§ {description}")
        print(f"  é…ç½®: {chunk_size}å—å¤§å°, {n_jobs}è¿›ç¨‹")
        print(f"  å®é™…å—æ•°: {num_chunks}")
        print(f"  æœ‰æ•ˆè¿›ç¨‹æ•°: {effective_processes}")
        print(f"  è¿›ç¨‹åˆ©ç”¨ç‡: {utilization:.1%}")
        print(f"  æµªè´¹è¿›ç¨‹æ•°: {wasted_processes}")
        
        if utilization < 0.5:
            print(f"  âš ï¸  è­¦å‘Š: ä¸¥é‡çš„è¿›ç¨‹èµ„æºæµªè´¹! ({utilization:.1%})")
        elif utilization < 0.7:
            print(f"  âš¡ æ³¨æ„: ä¸­ç­‰ç¨‹åº¦çš„èµ„æºæµªè´¹ ({utilization:.1%})")
        else:
            print(f"  âœ… è‰¯å¥½: è¿›ç¨‹åˆ©ç”¨ç‡è¾ƒé«˜ ({utilization:.1%})")
        print()


def run_baseline_comparison():
    """è¿è¡ŒåŸºå‡†å¯¹æ¯”æµ‹è¯• - å•è¿›ç¨‹ vs å¤šè¿›ç¨‹"""
    print("\nğŸ¯ å•è¿›ç¨‹åŸºå‡†å¯¹æ¯”æµ‹è¯•")
    print("=" * 80)
    
    test_configs = [
        (1000, "å°æ•°æ®é›†"),
        (3000, "ä¸­æ•°æ®é›†"), 
        (5000, "å¤§æ•°æ®é›†")
    ]
    
    for N, desc in test_configs:
        print(f"\nğŸ“¦ {desc}: {N} æ ·æœ¬ Ã— 20 ç‰¹å¾ Ã— 96 æ—¶é—´ç‚¹")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_data = create_large_test_data(N, 20, 96)
        
        configs = [
            ("å•è¿›ç¨‹åŸºå‡†", 1, 500, False, False),
            ("æ ‡å‡†å¤šè¿›ç¨‹", 8, 400, True, False),
            ("å…±äº«å†…å­˜ä¼˜åŒ–", 12, 800, True, True),
            ("æ™ºèƒ½ä¼˜åŒ–", 20, 1000, True, True),
        ]
        
        baseline_time = None
        
        for config_name, n_jobs, chunk_size, use_mp, use_sm in configs:
            print(f"\nğŸ§ª {config_name}:")
            
            args = HighEndServerTestArgs(n_jobs=n_jobs, chunk_size=chunk_size, use_shared_memory=use_sm)
            
            # åˆ›å»ºæ•°æ®ç®¡ç†å™¨
            manager = DualGAFDataManager.__new__(DualGAFDataManager, args)
            manager.args = args
            manager.n_jobs = n_jobs
            manager.use_multiprocessing = use_mp
            manager.chunk_size = chunk_size
            manager.use_shared_memory = use_sm
            
            try:
                start_time = time.time()
                
                if use_sm and use_mp:
                    result = manager.generate_gaf_matrix_shared_memory(test_data, "summation", False)
                elif use_mp:
                    result = manager.generate_gaf_matrix_parallel(test_data, "summation", False)
                else:
                    result = manager._generate_gaf_matrix_single(test_data, "summation", False)
                
                execution_time = time.time() - start_time
                
                print(f"  â±ï¸  æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
                
                if config_name == "å•è¿›ç¨‹åŸºå‡†":
                    baseline_time = execution_time
                    print(f"  ğŸ“Š åŸºå‡†æ—¶é—´å·²è®¾å®š")
                else:
                    if baseline_time:
                        speedup = baseline_time / execution_time
                        efficiency = speedup / n_jobs if n_jobs > 1 else 1.0
                        print(f"  ğŸš€ åŠ é€Ÿæ¯”: {speedup:.2f}x")
                        print(f"  âš¡ å¹¶è¡Œæ•ˆç‡: {efficiency:.2f} ({efficiency*100:.1f}%)")
                        
                        if speedup < 1.0:
                            print(f"  âš ï¸  è­¦å‘Š: å¤šè¿›ç¨‹åè€Œæ¯”å•è¿›ç¨‹æ…¢!")
                        elif efficiency < 0.3:
                            print(f"  âš ï¸  è­¦å‘Š: å¹¶è¡Œæ•ˆç‡è¿‡ä½ï¼Œå­˜åœ¨ä¸¥é‡èµ„æºæµªè´¹!")
                
                print(f"  âœ… è¾“å‡ºå½¢çŠ¶: {result.shape}")
                
            except Exception as e:
                print(f"  âŒ æµ‹è¯•å¤±è´¥: {e}")
            
            # æ¸…ç†å†…å­˜
            import gc
            gc.collect()


def test_intelligent_optimization():
    """æµ‹è¯•æ™ºèƒ½ä¼˜åŒ–é€»è¾‘"""
    print("\nğŸ§  æ™ºèƒ½ä¼˜åŒ–é€»è¾‘æµ‹è¯•")
    print("=" * 80)
    
    test_cases = [
        # (N, expected_behavior)
        (100, "åº”ä½¿ç”¨å•è¿›ç¨‹(æ•°æ®é‡å¤ªå°)"),
        (800, "åº”ä½¿ç”¨å°‘é‡è¿›ç¨‹"),
        (2000, "åº”æ™ºèƒ½è°ƒæ•´è¿›ç¨‹æ•°"),
        (5000, "åº”å……åˆ†åˆ©ç”¨å¤šè¿›ç¨‹"),
    ]
    
    for N, expected in test_cases:
        print(f"\nğŸ“¦ æµ‹è¯• {N} æ ·æœ¬: {expected}")
        
        test_data = create_large_test_data(N, 20, 96)
        
        # ä½¿ç”¨é…ç½®è¿›ç¨‹æ•°20çš„è®¾ç½®æµ‹è¯•æ™ºèƒ½è°ƒæ•´
        args = HighEndServerTestArgs(n_jobs=20, chunk_size=400)
        manager = DualGAFDataManager.__new__(DualGAFDataManager, args)
        manager.args = args
        manager.n_jobs = 20
        manager.use_multiprocessing = True
        manager.chunk_size = 400
        manager.use_shared_memory = True
        
        try:
            print(f"  é…ç½®: 20è¿›ç¨‹, 400å—å¤§å°")
            start_time = time.time()
            result = manager.generate_gaf_matrix_shared_memory(test_data, "summation", False)
            execution_time = time.time() - start_time
            
            print(f"  â±ï¸  å®é™…æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
            print(f"  âœ… æ™ºèƒ½ä¼˜åŒ–ç”Ÿæ•ˆï¼Œå½¢çŠ¶: {result.shape}")
            
        except Exception as e:
            print(f"  âŒ æµ‹è¯•å¤±è´¥: {e}")


def test_optimal_chunk_sizes():
    """æµ‹è¯•ä¸åŒå—å¤§å°çš„æ€§èƒ½"""
    print("\n" + "="*80)
    print("ğŸ”¬ å—å¤§å°ä¼˜åŒ–æµ‹è¯• (é’ˆå¯¹32æ ¸128GBæœåŠ¡å™¨)")
    print("="*80)
    
    # åˆ›å»ºå¤§è§„æ¨¡æµ‹è¯•æ•°æ®
    test_data = create_large_test_data(6000, 20, 96)
    
    chunk_sizes = [400, 600, 800, 1000, 1200]
    n_jobs_list = [12, 16, 20, 24]
    
    results = {}
    
    for chunk_size in chunk_sizes:
        for n_jobs in n_jobs_list:
            print(f"\nğŸ§ª æµ‹è¯•é…ç½®: chunk_size={chunk_size}, n_jobs={n_jobs}")
            
            args = HighEndServerTestArgs(n_jobs=n_jobs, chunk_size=chunk_size)
            manager = DualGAFDataManager.__new__(DualGAFDataManager, args)
            manager.args = args
            manager.n_jobs = args.n_jobs
            manager.use_multiprocessing = args.use_multiprocessing
            manager.chunk_size = args.chunk_size
            manager.use_shared_memory = args.use_shared_memory
            
            try:
                with performance_monitor():
                    result = manager.generate_gaf_matrix_shared_memory(test_data[:2000], "summation", False)
                
                config_key = f"chunk{chunk_size}_jobs{n_jobs}"
                # è¿™é‡Œå¯ä»¥è®°å½•å…·ä½“çš„æ€§èƒ½æŒ‡æ ‡
                print(f"  âœ… æˆåŠŸå®Œæˆï¼Œè¾“å‡ºå½¢çŠ¶: {result.shape}")
                
            except Exception as e:
                print(f"  âŒ é…ç½®å¤±è´¥: {e}")
            
            # æ¸…ç†å†…å­˜
            import gc
            gc.collect()


def test_cpu_utilization_optimization():
    """æµ‹è¯•CPUåˆ©ç”¨ç‡ä¼˜åŒ–"""
    print("\n" + "="*80)
    print("ğŸ–¥ï¸  CPUåˆ©ç”¨ç‡ä¼˜åŒ–æµ‹è¯•")
    print("="*80)
    
    # åˆ›å»ºä¸­ç­‰å¤§å°çš„æ•°æ®è¿›è¡Œç»†è‡´æµ‹è¯•
    test_data = create_large_test_data(4000, 20, 96)
    
    configs = [
        {"n_jobs": 8, "chunk_size": 500, "desc": "ä¿å®ˆé…ç½®"},
        {"n_jobs": 16, "chunk_size": 800, "desc": "å¹³è¡¡é…ç½®"},
        {"n_jobs": 20, "chunk_size": 1000, "desc": "æ¿€è¿›é…ç½®"},
        {"n_jobs": 24, "chunk_size": 1200, "desc": "æé™é…ç½®"},
    ]
    
    for config in configs:
        print(f"\nğŸ“Š {config['desc']}: {config['n_jobs']}è¿›ç¨‹, {config['chunk_size']}å—å¤§å°")
        
        args = HighEndServerTestArgs(
            n_jobs=config['n_jobs'], 
            chunk_size=config['chunk_size']
        )
        manager = DualGAFDataManager.__new__(DualGAFDataManager, args)
        manager.args = args
        manager.n_jobs = args.n_jobs
        manager.use_multiprocessing = args.use_multiprocessing
        manager.chunk_size = args.chunk_size
        manager.use_shared_memory = args.use_shared_memory
        
        # ç›‘æ§CPUä½¿ç”¨ç‡
        cpu_percentages = []
        
        def monitor_cpu():
            for _ in range(20):  # ç›‘æ§20ç§’
                cpu_percentages.append(psutil.cpu_percent(interval=1))
        
        import threading
        monitor_thread = threading.Thread(target=monitor_cpu)
        monitor_thread.daemon = True
        monitor_thread.start()
        
        try:
            start_time = time.time()
            result = manager.generate_gaf_matrix_shared_memory(test_data, "summation", False)
            end_time = time.time()
            
            # ç­‰å¾…ç›‘æ§å®Œæˆ
            monitor_thread.join(timeout=1)
            
            avg_cpu = np.mean(cpu_percentages) if cpu_percentages else 0
            max_cpu = np.max(cpu_percentages) if cpu_percentages else 0
            
            print(f"  â±ï¸  æ‰§è¡Œæ—¶é—´: {end_time - start_time:.2f}ç§’")
            print(f"  ğŸ–¥ï¸  å¹³å‡CPUåˆ©ç”¨ç‡: {avg_cpu:.1f}%")
            print(f"  ğŸ“ˆ å³°å€¼CPUåˆ©ç”¨ç‡: {max_cpu:.1f}%")
            print(f"  âœ… è¾“å‡ºå½¢çŠ¶: {result.shape}")
            
        except Exception as e:
            print(f"  âŒ æµ‹è¯•å¤±è´¥: {e}")


def test_memory_vs_computation_workloads():
    """å¯¹æ¯”å†…å­˜å¯†é›†å‹vsè®¡ç®—å¯†é›†å‹å·¥ä½œè´Ÿè½½"""
    print("\n" + "="*80)
    print("âš–ï¸  å†…å­˜å¯†é›†å‹ vs è®¡ç®—å¯†é›†å‹è´Ÿè½½å¯¹æ¯”")
    print("="*80)
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_data = create_large_test_data(3000, 20, 96)
    
    print(f"\nğŸ§® è®¡ç®—å¯†é›†å‹æµ‹è¯• (GAFç”Ÿæˆ)")
    print("="*50)
    
    # GAFç”Ÿæˆæµ‹è¯• (è®¡ç®—å¯†é›†å‹)
    args_gaf = HighEndServerTestArgs(n_jobs=20, chunk_size=800)
    manager_gaf = DualGAFDataManager.__new__(DualGAFDataManager, args_gaf)
    manager_gaf.args = args_gaf
    manager_gaf.n_jobs = args_gaf.n_jobs
    manager_gaf.use_multiprocessing = args_gaf.use_multiprocessing
    manager_gaf.chunk_size = args_gaf.chunk_size
    manager_gaf.use_shared_memory = args_gaf.use_shared_memory
    
    print("ğŸš€ ä½¿ç”¨å…±äº«å†…å­˜:")
    with performance_monitor():
        gaf_result = manager_gaf.generate_gaf_matrix_shared_memory(test_data, "summation", False)
    
    print("ğŸ”§ ä½¿ç”¨æ ‡å‡†å¤šè¿›ç¨‹:")
    manager_gaf.use_shared_memory = False
    with performance_monitor():
        gaf_result_std = manager_gaf.generate_gaf_matrix_parallel(test_data, "summation", False)
    
    print(f"\nğŸ”„ å†…å­˜å¯†é›†å‹æµ‹è¯• (æ•°æ®è½¬æ¢)")
    print("="*50)
    
    # æ•°æ®è½¬æ¢æµ‹è¯• (å†…å­˜å¯†é›†å‹)
    # ä½¿ç”¨ä¹‹å‰ç”Ÿæˆçš„GAFæ•°æ®
    gaf_data = gaf_result[:2000]  # å–éƒ¨åˆ†æ•°æ®è¿›è¡Œè½¬æ¢æµ‹è¯•
    
    args_conv = HighEndServerTestArgs(n_jobs=8, chunk_size=400)  # è½¬æ¢ç”¨è¾ƒå°‘è¿›ç¨‹
    manager_conv = DualGAFDataManager.__new__(DualGAFDataManager, args_conv)
    manager_conv.args = args_conv
    manager_conv.data_type_method = 'uint8'
    manager_conv.n_jobs = args_conv.n_jobs
    manager_conv.use_multiprocessing = args_conv.use_multiprocessing
    manager_conv.chunk_size = args_conv.chunk_size
    manager_conv.use_shared_memory = args_conv.use_shared_memory
    
    print("ğŸš€ ä½¿ç”¨å…±äº«å†…å­˜:")
    with performance_monitor():
        try:
            conv_result = manager_conv.convert_gaf_data_type_shared_memory(gaf_data)
        except:
            print("  ğŸ“ å…±äº«å†…å­˜è½¬æ¢è¢«è·³è¿‡ï¼ˆæŒ‰è®¾è®¡ï¼Œå†…å­˜å¯†é›†å‹ä»»åŠ¡ä¼˜å…ˆä½¿ç”¨å¤šçº¿ç¨‹ï¼‰")
    
    print("ğŸ”§ ä½¿ç”¨æ ‡å‡†å¤šçº¿ç¨‹:")
    with performance_monitor():
        conv_result_std = manager_conv._gaf_to_int_parallel(gaf_data, dtype=np.uint8)


def print_server_optimization_recommendations():
    """æ‰“å°é’ˆå¯¹é«˜ç«¯æœåŠ¡å™¨çš„ä¼˜åŒ–å»ºè®®"""
    print("\n" + "="*80)
    print("ğŸ“‹ é’ˆå¯¹32æ ¸128GBæœåŠ¡å™¨çš„ä¼˜åŒ–å»ºè®®")
    print("="*80)
    
    print("ğŸ¯ **æ¨èé…ç½®**:")
    print("  GAFç”Ÿæˆ (è®¡ç®—å¯†é›†å‹):")
    print("    --n_jobs 20 --chunk_size 800 --use_shared_memory")
    print("  æ•°æ®è½¬æ¢ (å†…å­˜å¯†é›†å‹):")
    print("    --n_jobs 8 --chunk_size 400 (è‡ªåŠ¨é€‰æ‹©å¤šçº¿ç¨‹)")
    
    print("\nğŸ”§ **ç³»ç»Ÿçº§ä¼˜åŒ–**:")
    print("  1. è®¾ç½®NUMAç­–ç•¥: numactl --interleave=all")
    print("  2. å¢å¤§å…±äº«å†…å­˜: echo 67108864 > /proc/sys/kernel/shmmax")
    print("  3. ä¼˜åŒ–CPUè°ƒåº¦: echo performance > /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor")
    
    print("\nâš ï¸  **é¿å…çš„é…ç½®**:")
    print("  1. è¿›ç¨‹æ•°è¿‡å¤š (>24): å¯¼è‡´ä¸Šä¸‹æ–‡åˆ‡æ¢å¼€é”€")
    print("  2. å—å¤§å°è¿‡å° (<400): å¢åŠ é€šä¿¡å¼€é”€")
    print("  3. æ•°æ®è½¬æ¢å¼ºåˆ¶ä½¿ç”¨å…±äº«å†…å­˜: åè€Œé™ä½æ€§èƒ½")
    
    print("\nğŸ“Š **æ€§èƒ½é¢„æœŸ**:")
    print("  ä¼˜åŒ–å‰: GAFç”Ÿæˆ~90s, æ•°æ®è½¬æ¢~10s")
    print("  ä¼˜åŒ–å: GAFç”Ÿæˆ~60s, æ•°æ®è½¬æ¢~8s")
    print("  æ€»ä½“æå‡: ~30%")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ é«˜ç«¯æœåŠ¡å™¨æ€§èƒ½ä¼˜åŒ–æµ‹è¯• (å¢å¼ºç‰ˆ)")
    print("="*80)
    
    # æ£€æŸ¥ç³»ç»Ÿé…ç½®
    cpu_count = mp.cpu_count()
    memory = psutil.virtual_memory()
    print(f"ğŸ–¥ï¸  æ£€æµ‹åˆ°ç³»ç»Ÿé…ç½®:")
    print(f"  CPUæ ¸å¿ƒæ•°: {cpu_count}")
    print(f"  æ€»å†…å­˜: {memory.total / 1024**3:.1f}GB")
    print(f"  å¯ç”¨å†…å­˜: {memory.available / 1024**3:.1f}GB")
    print()
    
    if cpu_count < 16 or memory.total / 1024**3 < 32:
        print("âš ï¸  è­¦å‘Š: å½“å‰ç³»ç»Ÿé…ç½®è¾ƒä½ï¼Œæµ‹è¯•ç»“æœå¯èƒ½ä¸å‡†ç¡®")
        print()
    
    try:
        # æ–°å¢çš„åˆ†ææµ‹è¯•
        analyze_process_utilization()
        run_baseline_comparison()
        test_intelligent_optimization()
        
        # åŸæœ‰çš„æ€§èƒ½æµ‹è¯•
        test_optimal_chunk_sizes()
        test_cpu_utilization_optimization()
        test_memory_vs_computation_workloads()
        
        # æœ€ç»ˆå»ºè®®
        print_server_optimization_recommendations()
        
        print("\nğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
        print("=" * 80)
        print("ğŸ’¡ å…³é”®å‘ç°:")
        print("  1. è¿›ç¨‹åˆ©ç”¨ç‡åˆ†ææ˜¾ç¤ºäº†èµ„æºæµªè´¹çš„ä¸¥é‡ç¨‹åº¦")
        print("  2. å•è¿›ç¨‹åŸºå‡†å¯¹æ¯”æ­ç¤ºäº†å¹¶è¡ŒåŒ–çš„çœŸå®æ•ˆæœ")
        print("  3. æ™ºèƒ½ä¼˜åŒ–èƒ½å¤Ÿè‡ªåŠ¨è°ƒæ•´é…ç½®é¿å…èµ„æºæµªè´¹")
        print("  4. å—å¤§å°å’Œè¿›ç¨‹æ•°éœ€è¦æ ¹æ®æ•°æ®é‡åŠ¨æ€åŒ¹é…")
        print()
        print("âš ï¸  é¿å…çš„é…ç½®é™·é˜±:")
        print("  â€¢ è¿›ç¨‹æ•° > å®é™…å—æ•°ï¼šå¯¼è‡´å¤§é‡è¿›ç¨‹ç©ºé—²")
        print("  â€¢ å—å¤§å°è¿‡å°ï¼šå¢åŠ è¿›ç¨‹é—´é€šä¿¡å¼€é”€")
        print("  â€¢ ç›²ç›®å¢åŠ è¿›ç¨‹æ•°ï¼šå¯èƒ½åè€Œé™ä½æ€§èƒ½")
        print()
        print("ğŸ¯ ä¼˜åŒ–å»ºè®®:")
        print("  â€¢ ç¡®ä¿æ¯ä¸ªè¿›ç¨‹å¤„ç†è¶³å¤Ÿçš„æ•°æ®é‡(>100æ ·æœ¬)")
        print("  â€¢ å—æ•°åº”æ¥è¿‘æˆ–ç•¥å¤§äºè¿›ç¨‹æ•°")
        print("  â€¢ å¯¹å°æ•°æ®é›†ç›´æ¥ä½¿ç”¨å•è¿›ç¨‹")
        print("  â€¢ å¯ç”¨æ™ºèƒ½é…ç½®è‡ªåŠ¨ä¼˜åŒ–")
        
        print(f"\nğŸ‰ å¢å¼ºç‰ˆé«˜ç«¯æœåŠ¡å™¨ä¼˜åŒ–æµ‹è¯•å®Œæˆ!")
        print("  åŒ…å«äº†è¿›ç¨‹åˆ©ç”¨ç‡åˆ†æã€åŸºå‡†å¯¹æ¯”å’Œæ™ºèƒ½ä¼˜åŒ–éªŒè¯")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main()) 