#!/bin/bash

# å®‰å…¨è¿è¡ŒDualGAFç½‘ç»œè„šæœ¬ - ä¿®å¤å†…å­˜åŒé‡é‡Šæ”¾é”™è¯¯
echo "ğŸ›¡ï¸ å®‰å…¨è¿è¡ŒDualGAFç½‘ç»œ - å†…å­˜é”™è¯¯ä¿®å¤ç‰ˆ"
echo "=========================================="

# è®¾ç½®ç¯å¢ƒå˜é‡é˜²æ­¢å†…å­˜é—®é¢˜
export CUDA_LAUNCH_BLOCKING=1
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128
export OMP_NUM_THREADS=1

# åŸºç¡€é…ç½®
model="DualGAFNet"
data="DualGAF"
root_path="./dataset/SAHU"
seq_len=96
step=4
epochs=20
batch_size=4  # ä½¿ç”¨å°batch size
learning_rate=0.001
large_feature_dim=64
# æ¢¯åº¦ç´¯ç§¯é…ç½®ï¼šå°batch_size + æ¢¯åº¦ç´¯ç§¯ = æ›´å¤§çš„æœ‰æ•ˆbatch_size
gradient_accumulation_steps=4  # æœ‰æ•ˆbatch_size = 4 * 4 = 16

echo "å®éªŒ1: å®‰å…¨é…ç½®æµ‹è¯• (batch_size=${batch_size}, GA_steps=${gradient_accumulation_steps}, æœ‰æ•ˆbatch_size=$((batch_size * gradient_accumulation_steps)))"
python run.py \
    --model $model \
    --data $data \
    --root_path $root_path \
    --seq_len $seq_len \
    --step $step \
    --feature_dim $large_feature_dim \
    --extractor_type resnet18_gaf \
    --fusion_type adaptive \
    --attention_type channel \
    --classifier_type mlp \
    --use_statistical_features \
    --stat_type basic \
    --multimodal_fusion_strategy concat \
    --train_epochs $epochs \
    --batch_size $batch_size \
    --learning_rate $learning_rate \
    --gradient_accumulation_steps $gradient_accumulation_steps \
    --loss_preset standard \
    --ablation_mode none \
    --lr_scheduler_type f1_based \
    --num_workers 0 \
    --safe_mode \
    --des "safe_run_with_GA"

echo "å®‰å…¨å®éªŒå®Œæˆ"

echo ""
echo "ğŸ’¡ æ¢¯åº¦ç´¯ç§¯è¯´æ˜:"
echo "   - ç‰©ç†batch_size: ${batch_size}"
echo "   - æ¢¯åº¦ç´¯ç§¯æ­¥æ•°: ${gradient_accumulation_steps}"
echo "   - æœ‰æ•ˆbatch_size: $((batch_size * gradient_accumulation_steps))"
echo "   - å†…å­˜ä½¿ç”¨: ä»…å ç”¨${batch_size}ä¸ªæ ·æœ¬çš„å†…å­˜"
echo "   - è®­ç»ƒæ•ˆæœ: ç­‰æ•ˆäº${batch_size}x${gradient_accumulation_steps}çš„å¤§batchè®­ç»ƒ" 