#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•è„šæœ¬ï¼šéªŒè¯åˆ†ç»„ç‰¹å¾æå–åŠŸèƒ½

ä½¿ç”¨ç¤ºä¾‹:
python test_grouped_feature_extraction.py
"""

import torch
import torch.nn as nn
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_grouped_feature_extraction():
    """æµ‹è¯•åˆ†ç»„ç‰¹å¾æå–åŠŸèƒ½"""
    print("=" * 80)
    print("æµ‹è¯•HVACåˆ†ç»„ç‰¹å¾æå–ç½‘ç»œ")
    print("=" * 80)
    
    try:
        from models.MultiImageFeatureNet import Model
        
        # è®¾ç½®æµ‹è¯•å‚æ•°
        B, C, H, W = 2, 10, 32, 32
        x = torch.randn(B, C, H, W)
        
        # æ¨¡æ‹ŸHVACç‰¹å¾åˆ—å
        feature_columns = [
            'SA_TEMP', 'OA_TEMP', 'MA_TEMP',     # æ¸©åº¦ç»„
            'OA_CFM', 'RA_CFM',                  # æµé‡ç»„
            'SA_SP', 'SA_SPSPT',                 # è®¾å®šç‚¹ç»„
            'CHW_VLV_POS', 'HW_VLV_POS',        # é˜€é—¨ç»„
            'UNKNOWN_SIGNAL'                     # æœªçŸ¥ä¿¡å·ï¼ˆæµ‹è¯•é»˜è®¤ç»„ï¼‰
        ]
        
        # åˆ›å»ºé…ç½®
        configs = type("Config", (), {
            "feature_dim": 32, 
            "num_class": 5, 
            "enc_in": C,
            "feature_columns": feature_columns,
            "hvac_groups": [
                ['SA_TEMP', 'OA_TEMP', 'MA_TEMP', 'RA_TEMP'],  # æ¸©åº¦ç»„
                ['OA_CFM', 'RA_CFM', 'SA_CFM'],                 # æµé‡ç»„
                ['SA_SP', 'SA_SPSPT'],                          # è®¾å®šç‚¹ç»„
                ['CHW_VLV_POS', 'HW_VLV_POS'],                  # é˜€é—¨ç»„
            ]
        })()
        
        print(f"1. æµ‹è¯•å‚æ•°:")
        print(f"   è¾“å…¥ç»´åº¦: {x.shape}")
        print(f"   ç‰¹å¾åˆ—æ•°: {len(feature_columns)}")
        print(f"   ä¿¡å·ç»„æ•°: {len(configs.hvac_groups)}")
        print(f"   ç±»åˆ«æ•°: {configs.num_class}")
        
        print(f"\n2. ç‰¹å¾åˆ—å:")
        for i, col in enumerate(feature_columns):
            print(f"   é€šé“{i}: {col}")
        
        print(f"\n3. ä¿¡å·åˆ†ç»„:")
        for i, group in enumerate(configs.hvac_groups):
            print(f"   ç»„{i}: {group}")
        
        # åˆ›å»ºæ¨¡å‹
        print(f"\n4. åˆ›å»ºæ¨¡å‹...")
        model = Model(configs)
        
        print(f"\n5. é€šé“åˆ†ç»„æ˜ å°„:")
        for channel_idx, group_idx in model.model.channel_to_group.items():
            col_name = feature_columns[channel_idx] if channel_idx < len(feature_columns) else "Unknown"
            group_name = f"group_{group_idx}" if group_idx >= 0 else "default"
            print(f"   é€šé“{channel_idx} ({col_name}) -> {group_name}")
        
        print(f"\n6. ç‰¹å¾æå–å™¨:")
        for name, extractor in model.model.feature_extractors.items():
            print(f"   {name}: {type(extractor).__name__}")
        
        # æµ‹è¯•forwardè¿‡ç¨‹
        print(f"\n7. æµ‹è¯•å‰å‘ä¼ æ’­...")
        model.eval()
        with torch.no_grad():
            output = model(x)
        
        print(f"   è¾“å‡ºç»´åº¦: {output.shape}")
        print(f"   è¾“å‡ºèŒƒå›´: [{output.min().item():.4f}, {output.max().item():.4f}]")
        
        # æµ‹è¯•æ¢¯åº¦ä¼ æ’­
        print(f"\n8. æµ‹è¯•æ¢¯åº¦ä¼ æ’­...")
        model.train()
        output = model(x)
        loss = output.sum()
        loss.backward()
        
        gradients_exist = any(p.grad is not None for p in model.parameters())
        print(f"   æ¢¯åº¦æ˜¯å¦å­˜åœ¨: {'æ˜¯' if gradients_exist else 'å¦'}")
        
        # å‚æ•°ç»Ÿè®¡
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"\n9. æ¨¡å‹ç»Ÿè®¡:")
        print(f"   æ€»å‚æ•°æ•°é‡: {total_params:,}")
        print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        print(f"   ç‰¹å¾æå–å™¨æ•°é‡: {len(model.model.feature_extractors)}")
        
        print(f"\nâœ“ åˆ†ç»„ç‰¹å¾æå–åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        
        return True
        
    except Exception as e:
        print(f"âœ— æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_backward_compatibility():
    """æµ‹è¯•å‘åå…¼å®¹æ€§ï¼ˆä¸æä¾›åˆ†ç»„ä¿¡æ¯æ—¶çš„é»˜è®¤è¡Œä¸ºï¼‰"""
    print("\n" + "=" * 80)
    print("æµ‹è¯•å‘åå…¼å®¹æ€§")
    print("=" * 80)
    
    try:
        from models.MultiImageFeatureNet import Model
        
        # ä¸æä¾›åˆ†ç»„ä¿¡æ¯çš„é…ç½®
        configs = type("Config", (), {
            "num_class": 4, 
            "enc_in": 10,
        })()
        
        print(f"1. åˆ›å»ºæ²¡æœ‰åˆ†ç»„ä¿¡æ¯çš„æ¨¡å‹...")
        model = Model(configs)
        
        print(f"2. æ¨¡å‹é»˜è®¤è¡Œä¸º:")
        print(f"   ä½¿ç”¨é»˜è®¤HVACåˆ†ç»„: {len(model.model.hvac_groups)} ç»„")
        print(f"   ç‰¹å¾æå–å™¨æ•°é‡: {len(model.model.feature_extractors)}")
        
        # æµ‹è¯•forward
        x = torch.randn(2, 10, 32, 32)
        output = model(x)
        print(f"   è¾“å‡ºç»´åº¦: {output.shape}")
        
        print(f"\nâœ“ å‘åå…¼å®¹æ€§æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"âœ— å‘åå…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("å¼€å§‹æµ‹è¯•åˆ†ç»„ç‰¹å¾æå–åŠŸèƒ½...")
    
    success1 = test_grouped_feature_extraction()
    success2 = test_backward_compatibility()
    
    if success1 and success2:
        print("\n" + "=" * 80)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼åˆ†ç»„ç‰¹å¾æå–åŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚")
        print("=" * 80)
    else:
        print("\n" + "=" * 80)
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ã€‚")
        print("=" * 80) 